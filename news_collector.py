# news_collector.py
import os
import smtplib
import platform
import base64
import markdown
import json
import time
import random
from weather_service import WeatherService 
from risk_briefing_service import RiskBriefingService
from utils import get_kst_today_str,get_kst_week_str, markdown_to_html, image_to_base64_string
import logging
from datetime import datetime, timezone, timedelta, date
from email.mime.text import MIMEText
from email.mime.image import MIMEImage
from email.mime.multipart import MIMEMultipart
from email.utils import formataddr
from urllib.parse import urljoin, urlparse
from io import BytesIO
from concurrent.futures import ProcessPoolExecutor, as_completed
import re
from newspaper import Article
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
from matplotlib.ticker import FuncFormatter
# ì„œë“œíŒŒí‹° ë¼ì´ë¸ŒëŸ¬ë¦¬
import requests
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
from bs4 import BeautifulSoup
from jinja2 import Environment, FileSystemLoader
from PIL import Image
from pygooglenews import GoogleNews
from zoneinfo import ZoneInfo

# â¬‡ï¸â¬‡ï¸â¬‡ï¸ Seleniumì˜ 'ì§€ëŠ¥ì  ê¸°ë‹¤ë¦¼' ê¸°ëŠ¥ì„ ìœ„í•œ ì„í¬íŠ¸ ì¶”ê°€ â¬‡ï¸â¬‡ï¸â¬‡ï¸
from selenium import webdriver
from selenium.webdriver.chrome.service import Service as ChromeService
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.chrome.options import Options
from selenium_stealth import stealth
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

# êµ¬ê¸€ ì¸ì¦ ê´€ë ¨
from google.auth.transport.requests import Request
from google.oauth2 import service_account
from google.oauth2.credentials import Credentials
from google_auth_oauthlib.flow import InstalledAppFlow
from googleapiclient.discovery import build
from googleapiclient.errors import HttpError
import openai

from config import Config

def _create_driver_for_process(driver_path: str): # âœ¨ ë“œë¼ì´ë²„ ê²½ë¡œë¥¼ ì¸ìë¡œ ë°›ìŒ
    """ê° í”„ë¡œì„¸ìŠ¤ë¥¼ ìœ„í•œ ë…ë¦½ì ì¸ Selenium ë“œë¼ì´ë²„ë¥¼ ìƒì„±í•˜ëŠ” í•¨ìˆ˜"""
    config = Config()
    chrome_options = Options()
    chrome_options.page_load_strategy = 'eager'
    chrome_options.add_argument("--headless=new") 
    chrome_options.add_argument(f'--user-agent={random.choice(config.USER_AGENTS)}')
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--disable-dev-shm-usage")
    chrome_options.add_argument("--log-level=3") 
    chrome_options.add_experimental_option('excludeSwitches', ['enable-logging'])
    chrome_options.add_argument("--blink-settings=imagesEnabled=false") 
    chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
    chrome_options.add_experimental_option('useAutomationExtension', False)
    chrome_options.add_argument("--disable-blink-features=AutomationControlled")
    try:
        # âœ¨ ë” ì´ìƒ ë“œë¼ì´ë²„ë¥¼ ë§¤ë²ˆ ì„¤ì¹˜í•˜ì§€ ì•Šê³ , ì „ë‹¬ë°›ì€ ê²½ë¡œë¥¼ ì‚¬ìš©
        service = ChromeService(executable_path=driver_path)
        driver = webdriver.Chrome(service=service, options=chrome_options)
        stealth(driver, languages=["ko-KR", "ko"], vendor="Google Inc.", platform="Win32",
                webgl_vendor="Intel Inc.", renderer="Intel Iris OpenGL Engine", fix_hairline=True)
        #driver.set_page_load_timeout(20)
        return driver
    except Exception as e:
        print(f"ğŸš¨ ë“œë¼ì´ë²„ ìƒì„± ì‹¤íŒ¨: {e}")
        return None


def _clean_and_validate_url_worker(url):
    """(ë…ë¦½ í•¨ìˆ˜) URLì˜ ìœ íš¨ì„±ì„ ê²€ì‚¬í•˜ê³  ì •ì œí•©ë‹ˆë‹¤."""
    config = Config()
    try:
        parsed = urlparse(url)
        if any(ad_domain in parsed.netloc for ad_domain in config.AD_DOMAINS_BLACKLIST):
            return None
        path = parsed.path.lower()
        is_likely_article = (
            any(char.isdigit() for char in path) or
            any(keyword in path for keyword in ['/news/', '/article/', '/view/']) or
            path.endswith('.html') or path.endswith('.php') or path.endswith('.do')
        )
        if 'hyundai.co.kr' in parsed.netloc:
            pass
        elif not is_likely_article:
            return None
        return parsed._replace(fragment="").geturl()
    except Exception:
        return None

def resolve_google_news_url_worker(entry, driver_path: str):
    start_time = time.time()
    title = entry['title']
    gnews_link = entry['link']
    print(f"[DEBUG] '{title}' URL ì¶”ì¶œ ì‹œì‘...")
    
    driver = None
    try:
        driver_start = time.time()
        driver = _create_driver_for_process(driver_path)
        if not driver: return None
        print(f"[DEBUG] '{title}' | ë“œë¼ì´ë²„ ìƒì„± | {time.time() - driver_start:.2f}s")

        get_start = time.time()
        driver.get(gnews_link)
        print(f"[DEBUG] '{title}' | driver.get() | {time.time() - get_start:.2f}s")
        
        wait_start = time.time()
        wait = WebDriverWait(driver, 30)
        link_element = wait.until(EC.presence_of_element_located((By.TAG_NAME, 'a')))
        print(f"[DEBUG] '{title}' | WebDriverWait | {time.time() - wait_start:.2f}s")

        original_url = link_element.get_attribute('href')
        validated_url = _clean_and_validate_url_worker(original_url)
        
        if validated_url:
            print(f" Â -> âœ… URL ì¶”ì¶œ ì„±ê³µ: {title} | ì´ ì†Œìš”ì‹œê°„: {time.time() - start_time:.2f}s")
            return {'title': title, 'link': validated_url}
        else:
            print(f"   ã„´> ğŸ—‘ï¸ ê¸°ì‚¬ URL íŒ¨í„´ì´ ì•„ë‹ˆë¼ì„œ ì œì™¸: {original_url}")
            return None
    except Exception as e:
        if 'TimeoutException' in e.__class__.__name__:
             print(f" Â ã„´> âŒ URL ì¶”ì¶œ íƒ€ì„ì•„ì›ƒ: '{title}' (í˜„ì¬ URL: {driver.current_url if driver else 'N/A'})")
        else:
             print(f" Â ã„´> âŒ URL ì¶”ì¶œ ì‹¤íŒ¨: '{title}'ì—ì„œ ì˜¤ë¥˜ ë°œìƒ: {e.__class__.__name__}")
        return None
    finally:
        if driver:
            driver.quit()


def process_article_content_worker(articles_batch, driver_path: str):
    processed_in_batch = []
    driver = None
    config = Config()
    scraper = NewsScraper(config)
    ai_service = AIService(config)

    for i, article_info in enumerate(articles_batch):
        batch_start_time = time.time()
        title = article_info['title']
        url = article_info['link']
        print(f"[DEBUG] '{title}' ì½˜í…ì¸  ì²˜ë¦¬ ì‹œì‘...")

        if i % 7 == 0:
            if driver: driver.quit()
            driver_start = time.time()
            driver = _create_driver_for_process(driver_path)
            print(f"[DEBUG] '{title}' | ìƒˆ ë“œë¼ì´ë²„ ìƒì„± | {time.time() - driver_start:.2f}s")
        if not driver:
            print("   ã„´> ğŸš¨ ë“œë¼ì´ë²„ê°€ ì—†ì–´ í˜„ì¬ ë°°ì¹˜ë¥¼ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
            break

        try:
            get_start = time.time()
            driver.get(url)
            print(f"[DEBUG] '{title}' | 1. driver.get() | {time.time() - get_start:.2f}s")
            
            wait_start = time.time()
            content_selectors = '#article-view-content, .article_body, .entry-content, #article-view, #articleBody, .post-content, #articles_detail'
            WebDriverWait(driver, 20).until(EC.presence_of_element_located((By.CSS_SELECTOR, content_selectors)))
            print(f"[DEBUG] '{title}' | 2. WebDriverWait | {time.time() - wait_start:.2f}s")
            
            html_content = driver.page_source
            soup = BeautifulSoup(html_content, 'lxml')
            content_area = soup.select_one(content_selectors)
            if not content_area: continue
            
            text_processing_start = time.time()
            article_text = content_area.get_text(strip=True)
            if len(article_text) < 300: continue
            print(f"[DEBUG] '{title}' | 3. ë³¸ë¬¸ í…ìŠ¤íŠ¸ ì²˜ë¦¬ | {time.time() - text_processing_start:.2f}s")

            summary_start = time.time()
            ai_summary = ai_service.generate_single_summary(title, url, article_text_from_selenium=article_text)
            if not ai_summary or "ìš”ì•½ ì •ë³´ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤" in ai_summary: continue
            print(f"[DEBUG] '{title}' | 4. AI ìš”ì•½ | {time.time() - summary_start:.2f}s")

            image_start = time.time()
            image_url = scraper.get_image_url(soup, url)
            print(f"[DEBUG] '{title}' | 5. ì´ë¯¸ì§€ URL ê²€ìƒ‰ | {time.time() - image_start:.2f}s")
            
            # ... (ì´í•˜ ì´ë¯¸ì§€ ì²˜ë¦¬ ë° ì €ì¥ ë¡œì§ì€ ë™ì¼)
            image_data, final_width, final_height = None, 0, 0
            if image_url and image_url != config.DEFAULT_IMAGE_URL:
                try:
                    img_dl_start = time.time()
                    img_response = scraper.session.get(image_url, timeout=10)
                    img_response.raise_for_status()
                    img = Image.open(BytesIO(img_response.content))
                    print(f"[DEBUG] '{title}' | 6. ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ | {time.time() - img_dl_start:.2f}s")
                    # ë¦¬ì‚¬ì´ì§• ë¡œì§ ...
                    original_width, original_height = img.size
                    if original_width < 640:
                        final_width, final_height = original_width, original_height
                        buffer = BytesIO()
                        if img.mode in ("RGBA", "P"): img = img.convert("RGB")
                        img.save(buffer, format='JPEG', quality=90)
                        image_data = buffer.getvalue()
                    else:
                        aspect_ratio = original_height / original_width
                        if aspect_ratio > 1.5:
                            target_height = min(original_height, 800)
                            target_width = int(target_height / aspect_ratio)
                            img = img.resize((target_width, target_height), Image.Resampling.LANCZOS)
                        else:
                            target_width = 640
                            target_height = int(target_width * aspect_ratio)
                            img = img.resize((target_width, target_height), Image.Resampling.LANCZOS)
                        final_width, final_height = img.size
                        buffer = BytesIO()
                        if img.mode in ("RGBA", "P"): img = img.convert("RGB")
                        img.save(buffer, format='JPEG', quality=85)
                        image_data = buffer.getvalue()
                except Exception: image_data = None
            if not image_data: continue
            
            processed_in_batch.append({'title': title, 'link': url, 'ai_summary': ai_summary, 'image_data': image_data, 'image_final_width': final_width, 'image_final_height': final_height})
            print(f" Â -> âœ… ì½˜í…ì¸  ì²˜ë¦¬ ì„±ê³µ: '{title}' | ì´ ì†Œìš”ì‹œê°„: {time.time() - batch_start_time:.2f}s")

        except Exception as e:
            if 'TimeoutException' in e.__class__.__name__:
                print(f" Â > âŒ ì½˜í…ì¸  ì²˜ë¦¬ íƒ€ì„ì•„ì›ƒ: '{title}' (í˜„ì¬ URL: {driver.current_url if driver else 'N/A'}) | ì´ ì†Œìš”ì‹œê°„: {time.time() - batch_start_time:.2f}s")
            else:
                print(f" Â ã„´> âŒ ì½˜í…ì¸  ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: '{title}' ({e.__class__.__name__}) | ì´ ì†Œìš”ì‹œê°„: {time.time() - batch_start_time:.2f}s")
            continue
    if driver:
        driver.quit()
    return processed_in_batch

def render_html_template(context, target='email'):
    """Jinja2 í…œí”Œë¦¿ì„ ë Œë”ë§í•©ë‹ˆë‹¤. targetì— ë”°ë¼ ì´ë¯¸ì§€ ê²½ë¡œë¥¼ ë‹¤ë¥´ê²Œ ì„¤ì •í•©ë‹ˆë‹¤."""
    env = Environment(loader=FileSystemLoader('.'))
    template = env.get_template('email_template.html')
    
    # contextì—ì„œ Base64 ë°ì´í„° ì¶”ì¶œ
    price_chart_b64 = context.get("price_indicators", {}).get("price_chart_b64")
    weather_dashboard_b64 = context.get("weather_dashboard_b64")

    context['target'] = target

    if target == 'web':
        # ì›¹í˜ì´ì§€ì—ì„œëŠ” Base64 ë°ì´í„° URIë¥¼ ì‚¬ìš©
        if price_chart_b64:
            context['price_chart_src'] = f"data:image/png;base64,{price_chart_b64}"
        if weather_dashboard_b64:
            context['weather_dashboard_src'] = f"data:image/png;base64,{weather_dashboard_b64}"
    else: # 'email'
        context['price_chart_src'] = 'cid:price_chart'
        context['weather_dashboard_src'] = 'cid:weather_dashboard'
    
    return template.render(context)
def format_change(change):
            if change > 0:
                return f"ì£¼ê°„ +{change:,.0f}ì› â–²"
            elif change < 0:
                return f"ì£¼ê°„ {change:,.0f}ì› â–¼"
            else:
                return "ì£¼ê°„ ë³€ë™ ì—†ìŒ"
            
def create_price_trend_chart(seven_day_data, today_str):
    """(ê°œì„ ) ìµœê·¼ 7ì¼ ìœ ê°€ ë°ì´í„°ë¡œ ê° ë‚ ì§œë³„ ê°€ê²©ì´ í‘œì‹œëœ ì°¨íŠ¸ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    filename = f"images/price_chart_{today_str}.png"
    try:
        # --- í°íŠ¸ ì„¤ì • (ê¸°ì¡´ê³¼ ë™ì¼) ---
        system_name = platform.system()
        if system_name == 'Windows':
            plt.rc('font', family='Malgun Gothic')
        elif system_name == 'Darwin':
            plt.rc('font', family='AppleGothic')
        else:
            font_path = '/usr/share/fonts/truetype/nanum/NanumGothicBold.ttf'
            if os.path.exists(font_path):
                # Matplotlibì˜ í°íŠ¸ ëª©ë¡ì— ë‚˜ëˆ”ê³ ë”•ì´ ì—†ìœ¼ë©´, ìºì‹œë¥¼ ì¬ìƒì„±
                if 'NanumGothic' not in [f.name for f in fm.fontManager.ttflist]:
                    print("-> ë‚˜ëˆ”ê³ ë”• í°íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ Matplotlib í°íŠ¸ ìºì‹œë¥¼ ì¬ìƒì„±í•©ë‹ˆë‹¤.")
                    fm._rebuild()
                plt.rc('font', family='NanumGothic') # 'NanumGothicBold' ëŒ€ì‹  'NanumGothic' ì‚¬ìš©ì´ ë” ì•ˆì •ì 
            else:
                print("âš ï¸ ë‚˜ëˆ”ê³ ë”• í°íŠ¸ íŒŒì¼ì´ ì—†ì–´ ê¸°ë³¸ í°íŠ¸ë¡œ ì¶œë ¥ë©ë‹ˆë‹¤.")
        plt.rcParams['axes.unicode_minus'] = False

        # --- ë°ì´í„° ì¤€ë¹„ (ê¸°ì¡´ê³¼ ë™ì¼) ---
        dates = [d['DATE'][-4:-2] + "/" + d['DATE'][-2:] for d in seven_day_data['gasoline']]
        gasoline_prices = [float(p['PRICE']) for p in seven_day_data['gasoline']]
        diesel_prices = [float(p['PRICE']) for p in seven_day_data['diesel']]
        
        # --- ê·¸ë˜í”„ ìƒì„± ---
        fig, ax = plt.subplots(figsize=(8, 5)) # ê·¸ë˜í”„ í¬ê¸°ë¥¼ ì•½ê°„ ì¡°ì •
        ax.plot(dates, gasoline_prices, 'o-', label='íœ˜ë°œìœ ', color='#3498db', linewidth=2)
        ax.plot(dates, diesel_prices, 'o-', label='ê²½ìœ ', color='#e74c3c', linewidth=2)
        
        ax.set_title("ìµœê·¼ 7ì¼ ìœ ê°€ ì¶”ì´", fontsize=16, pad=20, fontweight='bold')
        ax.legend()
        ax.grid(True, which='both', linestyle=':', linewidth=0.7)
        
        formatter = FuncFormatter(lambda y, _: f'{int(y):,}ì›')
        ax.yaxis.set_major_formatter(formatter)
        ax.tick_params(axis='x', rotation=0)
        
        # âœ¨ [ì‹ ê·œ] ê° ë°ì´í„° í¬ì¸íŠ¸ì— ê°€ê²© í…ìŠ¤íŠ¸ë¥¼ ì¶”ê°€í•˜ëŠ” ë¡œì§
        # va='bottom'ì€ í¬ì¸íŠ¸ ë°”ë¡œ ìœ„ì—, va='top'ì€ ë°”ë¡œ ì•„ë˜ì— í…ìŠ¤íŠ¸ë¥¼ ìœ„ì¹˜ì‹œí‚µë‹ˆë‹¤.
        for i, price in enumerate(gasoline_prices):
            ax.text(i, price + 5, f'{int(price):,}', ha='center', va='bottom', fontsize=9, color='#005a9c')
            
        for i, price in enumerate(diesel_prices):
            ax.text(i, price + 5, f'{int(price):,}', ha='center', va='bottom', fontsize=9, color='#a8382c')
        
        # Yì¶• ë²”ìœ„ë¥¼ ì‚´ì§ ëŠ˜ë ¤ì„œ ìœ„ìª½ í…ìŠ¤íŠ¸ê°€ ì˜ë¦¬ì§€ ì•Šë„ë¡ í•¨
        ymin, ymax = ax.get_ylim()
        ax.set_ylim(ymin, ymax * 1.05)
        
        fig.tight_layout()
        
        # --- íŒŒì¼ ì €ì¥ ë° ë°˜í™˜ (ê¸°ì¡´ê³¼ ë™ì¼) ---
        plt.savefig(filename, dpi=150)
        plt.close(fig)
        print(f"âœ… ìœ ê°€ ì¶”ì´ ì°¨íŠ¸ ì´ë¯¸ì§€ '{filename}'ë¥¼ ìƒì„±í–ˆìŠµë‹ˆë‹¤.")
        
        base64_image = image_to_base64_string(filename)
        return {"filepath": filename, "base64": base64_image}

    except Exception as e:
        print(f"âŒ ì°¨íŠ¸ ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨: {e}")
        return None
    
    
def get_price_indicators(config):
    """ì˜¤í”¼ë„· APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì£¼ìš” ë„ì‹œë³„ ìœ ê°€, ìš”ì†Œìˆ˜ ê°€ê²©, ì¶”ì„¸, ìµœì €ê°€ ì£¼ìœ ì†Œ ì •ë³´ë¥¼ ê°€ì ¸ì™€ í•˜ë‚˜ì˜ ê°ì²´ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤."""
    if not config.OPINET_API_KEY:
        print("âš ï¸ ì˜¤í”¼ë„· API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return {}

    # ìµœì¢… ë°ì´í„°ë¥¼ ë‹´ì„ ê¸°ë³¸ êµ¬ì¡° ì •ì˜
    indicator_data = {
        "timestamp": datetime.now(ZoneInfo('Asia/Seoul')).strftime('%Y-%m-%d %H:%M ê¸°ì¤€'),
        "city_prices": [],
        "trend_comment": "",
        "seven_day_data": {},
        "cheapest_stations": []
    }
    
    # --- 1. ì£¼ìš” ë„ì‹œë³„ íœ˜ë°œìœ /ê²½ìœ  ê°€ê²© ê°€ì ¸ì˜¤ê¸° (API í˜¸ì¶œ 1íšŒ) ---
    city_data_map = {code: {"name": name} for code, name in config.AREA_CODE_MAP.items() if code in config.TARGET_AREA_CODES}
    try:
        sido_price_url = f"http://www.opinet.co.kr/api/avgSidoPrice.do?out=json&code={config.OPINET_API_KEY}"
        response = requests.get(sido_price_url, timeout=30)
        response.raise_for_status()
        sido_data = response.json()['RESULT']['OIL']
        for oil in sido_data:
            area_code = oil.get('SIDOCD')
            if area_code in config.TARGET_AREA_CODES:
                prod_code = oil.get('PRODCD')
                price = f"{float(oil['PRICE']):,.0f}ì›"
                if prod_code == 'B027': # ë³´í†µíœ˜ë°œìœ 
                    city_data_map[area_code]['gasoline'] = price
                elif prod_code == 'D047': # ìë™ì°¨ìš©ê²½ìœ 
                    city_data_map[area_code]['diesel'] = price
        print("âœ… ì£¼ìš” ë„ì‹œë³„ ìœ ê°€ ì •ë³´ë¥¼ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"âŒ ì‹œë„ë³„ ìœ ê°€ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}")

    # --- 2. ì£¼ìš” ë„ì‹œë³„ ìš”ì†Œìˆ˜ í‰ê·  ê°€ê²© ê°€ì ¸ì˜¤ê¸° (ë„ì‹œë³„ API í˜¸ì¶œ) ---
    print("-> ì£¼ìš” ë„ì‹œë³„ ìš”ì†Œìˆ˜ ê°€ê²© ì •ë³´ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤...")
    for area_code in config.TARGET_AREA_CODES:
        urea_url = f"http://www.opinet.co.kr/api/ureaPrice.do?out=json&code={config.OPINET_API_KEY}&area={area_code}"
        try:
            response = requests.get(urea_url, timeout=30)
            response.raise_for_status()
            urea_data = json.loads(response.text, strict=False)['RESULT']['OIL']
            total_price, stock_count = 0, 0
            for station in urea_data:
                stock_yn = station.get('STOCK_YN', '').strip()
                price_str = station.get('PRICE', '').strip()
                if stock_yn == 'Y' and price_str:
                    total_price += int(price_str)
                    stock_count += 1
            if stock_count > 0:
                avg_price = total_price / stock_count
                city_data_map[area_code]['urea'] = f"{avg_price:,.0f}ì›/L"
            time.sleep(5)
        except Exception as e:
            area_name = config.AREA_CODE_MAP.get(area_code, "ì•Œ ìˆ˜ ì—†ëŠ” ì§€ì—­")
            print(f"âŒ {area_name} ìš”ì†Œìˆ˜ ê°€ê²© ì¡°íšŒ ì‹¤íŒ¨: {e}")
            continue
    print("âœ… ì£¼ìš” ë„ì‹œë³„ ìš”ì†Œìˆ˜ ê°€ê²© ì •ë³´ë¥¼ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤.")

    # --- 3. ì „êµ­ ê°€ê²© ì¶”ì„¸ ë° ì°¨íŠ¸ìš© ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (API í˜¸ì¶œ 1íšŒ) ---
    try:
        trend_url = f"http://www.opinet.co.kr/api/avgRecentPrice.do?out=json&code={config.OPINET_API_KEY}"
        response = requests.get(trend_url, timeout=30)
        response.raise_for_status()
        trend_data = response.json()['RESULT']['OIL']
        
        # ì°¨íŠ¸ìš© 7ì¼ ë°ì´í„° ì¤€ë¹„
        gasoline_7day = sorted([p for p in trend_data if p['PRODCD'] == 'B027'], key=lambda x: x['DATE'])
        diesel_7day = sorted([p for p in trend_data if p['PRODCD'] == 'D047'], key=lambda x: x['DATE'])
        if gasoline_7day and diesel_7day:
            indicator_data["seven_day_data"] = {"gasoline": gasoline_7day, "diesel": diesel_7day}
            print("âœ… ì°¨íŠ¸ìš© 7ì¼ ìœ ê°€ ë°ì´í„°ë¥¼ ì¤€ë¹„í–ˆìŠµë‹ˆë‹¤.")

        # ê²½ìœ  ê°€ê²© ì¶”ì„¸ ë¶„ì„
        if len(diesel_7day) >= 2:
            today_price = float(diesel_7day[-1]['PRICE'])
            yesterday_price = float(diesel_7day[-2]['PRICE'])
            trend_comment = ""
            if today_price > yesterday_price: trend_comment += "ì–´ì œë³´ë‹¤ ì†Œí­ ìƒìŠ¹í–ˆìŠµë‹ˆë‹¤."
            elif today_price < yesterday_price: trend_comment += "ì–´ì œë³´ë‹¤ ì†Œí­ í•˜ë½í–ˆìŠµë‹ˆë‹¤."
            else: trend_comment += "ì–´ì œì™€ ê°€ê²©ì´ ë™ì¼í•©ë‹ˆë‹¤."
            
            if len(diesel_7day) >= 7:
                week_ago_price = float(diesel_7day[0]['PRICE'])
                if today_price > week_ago_price: trend_comment += " ì£¼ê°„ ë‹¨ìœ„ë¡œëŠ” ìƒìŠ¹ì„¸ì…ë‹ˆë‹¤."
                elif today_price < week_ago_price: trend_comment += " ì£¼ê°„ ë‹¨ìœ„ë¡œëŠ” í•˜ë½ì„¸ì…ë‹ˆë‹¤."
            
            indicator_data["trend_comment"] = f"ì „êµ­ ê²½ìœ  ê°€ê²©ì€ {trend_comment}"
            print("âœ… ì „êµ­ ìœ ê°€ ì¶”ì„¸ ì •ë³´ë¥¼ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"âŒ ìœ ê°€ ì¶”ì„¸ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}")

    # --- 4. ì „êµ­ ìµœì €ê°€ ì£¼ìœ ì†Œ ì •ë³´ ê°€ì ¸ì˜¤ê¸° ---
    #indicator_data["cheapest_stations"] = get_cheapest_stations(config, count=20)

    # --- ìµœì¢… ë°ì´í„° êµ¬ì¡° ì •ë¦¬ ---
    indicator_data["city_prices"] = list(city_data_map.values())
    return indicator_data
    

class NewsScraper:
    def __init__(self, config):
        self.config = config
        self.session = self._create_session()

    def _create_session(self):
        session = requests.Session()
        retry = Retry(total=5, backoff_factor=1.0, status_forcelist=[429, 500, 502, 503, 504])
        adapter = HTTPAdapter(max_retries=retry)
        session.mount('http://', adapter)
        session.mount('https://', adapter)
        return session
    
    def _transform_thumbnail_url(self, url: str) -> str:
        """ì¸ë„¤ì¼ URLì„ ì›ë³¸ URLë¡œ ë³€í˜• ì‹œë„ (ì˜ˆ: _v150.jpg ì œê±°)"""
        # ì •ê·œí‘œí˜„ì‹ì„ ì‚¬ìš©í•˜ì—¬ URL ëì— ìˆëŠ” '_vìˆ«ì', '_wìˆ«ì', '_sìˆ«ì' ë“±ì˜ ì¸ë„¤ì¼ íŒ¨í„´ì„ ì œê±°
        transformed_url = re.sub(r'(_[vws]\d+)\.(jpg|jpeg|png|gif)$', r'.\2', url, flags=re.IGNORECASE)
        return transformed_url

    def get_image_url(self, soup: BeautifulSoup, base_url: str) -> str:
        try:
            # 1ìˆœìœ„: ë©”íƒ€ íƒœê·¸ (ì´ì œ soup ê°ì²´ì—ì„œ ë°”ë¡œ ì°¾ìŒ)
            meta_image = soup.find("meta", property="og:image") or soup.find("meta", name="twitter:image")
            if meta_image and meta_image.get("content"):
                thumbnail_url = meta_image["content"]
                original_url_candidate = self._transform_thumbnail_url(thumbnail_url)
                
                full_url = self._resolve_url(base_url, original_url_candidate)
                if self._is_valid_candidate(full_url) and self._validate_image(full_url):
                    return full_url
                
                full_thumbnail_url = self._resolve_url(base_url, thumbnail_url)
                if full_thumbnail_url != full_url:
                    if self._is_valid_candidate(full_thumbnail_url) and self._validate_image(full_thumbnail_url):
                        return full_thumbnail_url

            # 2ìˆœìœ„: íŠ¹ì • ê¸°ì‚¬ ë³¸ë¬¸ ì˜ì—­ ì•ˆì—ì„œ ì´ë¯¸ì§€ ê²€ìƒ‰
            content_area = soup.select_one('#article-view-content-div, .entry-content, .article-body, #article-view-content, #article-view, #articleBody, .post-content')
            if content_area:
                for img in content_area.find_all("img", limit=5):
                    img_url = img.get("src") or img.get("data-src")
                    if img_url and self._is_valid_candidate(img_url):
                        full_url = self._resolve_url(base_url, img_url)
                        if self._validate_image(full_url):
                            return full_url
            
            # 3ìˆœìœ„: ë³¸ë¬¸ <figure> ë˜ëŠ” <picture> íƒœê·¸
            for tag in soup.select('figure > img, picture > img', limit=5):
                img_url = tag.get('src') or tag.get('data-src') or (tag.get('srcset').split(',')[0].strip().split(' ')[0] if tag.get('srcset') else None)
                if img_url and self._is_valid_candidate(img_url):
                    full_url = self._resolve_url(base_url, img_url)
                    if self._validate_image(full_url):
                        return full_url
            
            # 4ìˆœìœ„: ì¼ë°˜ <img> íƒœê·¸
            for img in soup.find_all("img", limit=10):
                img_url = img.get("src") or img.get("data-src")
                if img_url and self._is_valid_candidate(img_url):
                    full_url = self._resolve_url(base_url, img_url)
                    if self._validate_image(full_url):
                        return full_url

            return self.config.DEFAULT_IMAGE_URL
        except Exception:
            return self.config.DEFAULT_IMAGE_URL

    def _resolve_url(self, base_url, image_url):
        if image_url.startswith('//'): return 'https:' + image_url
        return urljoin(base_url, image_url)

    def _is_valid_candidate(self, image_url):
        if 'news.google.com' in image_url or 'lh3.googleusercontent.com' in image_url: return False
        return not any(pattern in image_url.lower() for pattern in self.config.UNWANTED_IMAGE_PATTERNS)

    def _validate_image(self, image_url):
        try:
            response = self.session.get(image_url, stream=True, timeout=5)
            response.raise_for_status()
            content_type = response.headers.get('Content-Type', '').lower()
            if 'image' not in content_type: return False
            img_data = BytesIO(response.content)
            with Image.open(img_data) as img:
                width, height = img.size
                if width < self.config.MIN_IMAGE_WIDTH or height < self.config.MIN_IMAGE_HEIGHT: return False
                aspect_ratio = width / height
                if aspect_ratio > 4.0 or aspect_ratio < 0.25: return False
                

                return True
        except Exception:
            return False

class AIService:
    def generate_zodiac_horoscopes(self):
        """12ê°„ì§€ ë ë³„ ìš´ì„¸ë¥¼ 'ë¡œë””' í˜ë¥´ì†Œë‚˜ë¡œ ìƒì„±í•˜ì—¬ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤."""
        print("-> AI ë ë³„ ìš´ì„¸ ìƒì„±ì„ ì‹œì‘í•©ë‹ˆë‹¤... (í˜ë¥´ì†Œë‚˜: ë¡œë””)")
        zodiacs = ['ì¥', 'ì†Œ', 'í˜¸ë‘ì´', 'í† ë¼', 'ìš©', 'ë±€', 'ë§', 'ì–‘', 'ì›ìˆ­ì´', 'ë‹­', 'ê°œ', 'ë¼ì§€']
        horoscopes = []

        system_prompt = "ë„ˆëŠ” 'ë¡œë””'ë¼ëŠ” ì´ë¦„ì˜, ê¸ì • ì†Œì‹ì„ ì „í•´ì£¼ëŠ” 20ëŒ€ ì—¬ì„± ìºë¦­í„°ì•¼. ì˜¤ëŠ˜ì€ íŠ¹ë³„íˆ êµ¬ë…ìë“¤ì„ ìœ„í•´ 12ê°„ì§€ ë ë³„ ìš´ì„¸ë¥¼ ë´ì£¼ëŠ” í˜„ëª…í•œ ì¡°ì–¸ê°€ ì—­í• ì´ì•¼. '~í–ˆì–´ìš”', '~ëë‹ˆë‹¤' ê°™ì€ ê·€ì—½ê³  ìƒëƒ¥í•œ ë§íˆ¬ëŠ” ìœ ì§€í•˜ë˜, ë‹¨ìˆœí•œ ê¸ì • ë©”ì‹œì§€ê°€ ì•„ë‹Œ ê¹Šì´ ìˆëŠ” ìš´ì„¸ë¥¼ ì „ë‹¬í•´ì•¼ í•´. ì‘ë‹µì€ ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ë¶€íƒí•´!"
        
        for zodiac_name in zodiacs:
            user_prompt = f"""
            ì˜¤ëŠ˜ ë‚ ì§œì— ë§ì¶° '{zodiac_name}'ë  ìš´ì„¸ ì •ë³´ë¥¼ ìƒì„±í•´ ì¤˜.

            [ì‘ì—… ì§€ì‹œ]
            1.  **ì˜¤ëŠ˜ì˜ ìš´ì„¸ (fortune)**: ì•„ë˜ 4ê°€ì§€ ìš”ì†Œë¥¼ ëª¨ë‘ í¬í•¨í•´ì„œ, ê¸ì •ì ì´ë©´ì„œë„ ê¹Šì´ ìˆëŠ” ìš´ì„¸ ë©”ì‹œì§€ë¥¼ 2-3ì¤„ë¡œ ìš”ì•½í•´ ì¤˜.
                - **ì˜¤ëŠ˜ì˜ ê¸°ìš´ ë¬˜ì‚¬**: ê·¸ë‚ ì˜ ì „ë°˜ì ì¸ ì—ë„ˆì§€ íë¦„ì„ 'ì¼ìƒ ìƒí™œ'ì´ë‚˜ 'ìì—° í˜„ìƒ'ì— ë¹„ìœ í•´ì„œ ë¨¼ì € ì„¤ëª…í•´ì¤˜.
                - **êµ¬ì²´ì ì¸ ìƒí™©**: 'ì—…ë¬´', 'ì¸ê°„ê´€ê³„', 'ê¸ˆì „' ë“± íŠ¹ì • ë¶„ì•¼ë¥¼ ì–¸ê¸‰í•´ì¤˜.
                - **ê¸ì •ì  ê¸°íšŒ**: ì–´ë–¤ ì¢‹ì€ ê¸°íšŒê°€ ìƒê¸¸ ìˆ˜ ìˆëŠ”ì§€ ì•Œë ¤ì¤˜.
                - **ì¡°ì–¸ ë˜ëŠ” ì£¼ì˜ì **: ê¸°íšŒë¥¼ ì˜ ì¡ê¸° ìœ„í•œ ì¡°ì–¸ì´ë‚˜, ê°€ë³ê²Œ ì£¼ì˜í•´ì•¼ í•  ì ì„ 'ë‹¤ë§Œ, ~' í˜•ì‹ìœ¼ë¡œ ì‚´ì§ ë§ë¶™ì—¬ì¤˜.
            
            2.  **ì˜¤ëŠ˜ì˜ ë¯¸ì…˜ (daily_mission)**: ì˜¤ëŠ˜ í•˜ë£¨ ì‹¤ì²œí•˜ë©´ í–‰ìš´ì„ ê°€ì ¸ë‹¤ì¤„ ì‘ê³  ê·€ì—¬ìš´ ë¯¸ì…˜ í•˜ë‚˜ë¥¼ ì œì•ˆí•´ ì¤˜. (ì˜ˆ: 'ì ì‹¬ ë¨¹ê³  5ë¶„ ì‚°ì±…í•˜ê¸°', 'ê°€ì¥ ì¢‹ì•„í•˜ëŠ” ë…¸ë˜ ë“£ê¸°' ë“±)
            3.  **í–‰ìš´ì˜ ì•„ì´í…œ (lucky_item)**: ì˜¤ëŠ˜ ì§€ë‹ˆê³  ë‹¤ë‹ˆë©´ ì¢‹ì€ í–‰ìš´ì˜ ì•„ì´í…œì„ í•œ ê°€ì§€ ì•Œë ¤ì¤˜. (ì˜ˆ: 'ì†ìˆ˜ê±´', 'íŒŒë€ìƒ‰ íœ' ë“± ì¼ìƒì ì¸ ë¬¼ê±´ìœ¼ë¡œ!)
            4.  **í–‰ìš´ì˜ ìƒ‰ìƒ (lucky_color)**: ì´ ë ì˜ ì—ë„ˆì§€ë¥¼ ì˜¬ë ¤ì¤„ í–‰ìš´ì˜ ìƒ‰ìƒ í•˜ë‚˜ë¥¼ ì¶”ì²œí•´ ì¤˜.
            5.  **ì˜ ë§ëŠ” ë  (compatible_sign)**: ì˜¤ëŠ˜ í•¨ê»˜í•˜ë©´ ì‹œë„ˆì§€ê°€ í­ë°œí•  ê²ƒ ê°™ì€ ì°°ë–¡ê¶í•© ë ë¥¼ í•˜ë‚˜ë§Œ ì•Œë ¤ì¤˜.

            [ì°¸ê³ : ë‹¤ì–‘í•œ ì¼ìƒ ë¹„ìœ ]
            - 'ìƒì¾Œí•œ ì•„ì¹¨ ê³µê¸°', 'ë°°í„°ë¦¬ 100% ì¶©ì „', 'ë°© ì²­ì†Œ', 'ë§‘ê²Œ ê°  í•˜ëŠ˜', 'ìƒˆë¡œìš´ ë…¸ë˜ ë°œê²¬' ë“± ëˆ„êµ¬ë‚˜ ê³µê°í•  ìˆ˜ ìˆëŠ” í‘œí˜„ì„ ì°½ì˜ì ìœ¼ë¡œ í™œìš©í•´ ë´!

            [ì¶œë ¥ í˜•ì‹]
            - ë°˜ë“œì‹œ ì•„ë˜ì™€ ê°™ì€ í‚¤ë¥¼ ê°€ì§„ JSON ê°ì²´ë¡œë§Œ ì‘ë‹µí•´ì•¼ í•´.
            - ì˜ˆì‹œ: {{"fortune": "...", "lucky_color": "...", "compatible_sign": "...", "daily_mission": "...", "lucky_item": "..."}}
            """
            
            print(f"  -> '{zodiac_name}'ë  ìš´ì„¸ ìš”ì²­ ì¤‘...")
            response_text = self._generate_content_with_retry(system_prompt, user_prompt, is_json=True)
            
            if response_text:
                try:
                    horoscope_data = json.loads(response_text)
                    horoscope_data['name'] = zodiac_name # ë”•ì…”ë„ˆë¦¬ì— ë  ì´ë¦„ ì¶”ê°€
                    horoscopes.append(horoscope_data)
                except (json.JSONDecodeError, KeyError) as e:
                    print(f"  âŒ '{zodiac_name}'ë  ìš´ì„¸ íŒŒì‹± ì‹¤íŒ¨: {e}. í•´ë‹¹ ë ëŠ” ì œì™¸ë©ë‹ˆë‹¤.")
            else:
                print(f"  âŒ '{zodiac_name}'ë  ìš´ì„¸ ìƒì„± ì‹¤íŒ¨. API ì‘ë‹µ ì—†ìŒ.")

        if horoscopes:
            print("âœ… AI ë ë³„ ìš´ì„¸ ìƒì„± ì™„ë£Œ!")
        return horoscopes
    
    def generate_risk_briefing(self, risk_events):
        if not risk_events:
            return None
            
        print("-> AI ë¬¼ë¥˜ ë¦¬ìŠ¤í¬ ë¸Œë¦¬í•‘ ìƒì„± ì‹œì‘... (í˜ë¥´ì†Œë‚˜: ë¡œë””)")

        event_context = "\n".join(
            [f"- ë‚ ì§œ: {e['date'].strftime('%Y-%m-%d')}, êµ­ê°€: {e['country']}, ì´ë²¤íŠ¸: {e['name']}, ë¦¬ìŠ¤í¬ ìˆ˜ì¤€: {e['risk_level']}, ì˜ˆìƒ ì˜í–¥: {e['impact_summary']}" for e in risk_events]
        )

        system_prompt = "ë°˜ê°€ì›Œ! ë‚˜ëŠ” ë¯¸ë˜ì˜ ë¬¼ë¥˜ ë¦¬ìŠ¤í¬ë¥¼ ì½•ì½• ì§šì–´ì£¼ëŠ” ë„ˆì˜ ì•ˆì „ íŒŒíŠ¸ë„ˆ, ë¡œë””ë¼ê³  í•´! ğŸ˜‰ ë‚˜ëŠ” 20ëŒ€ ì—¬ì„± ìºë¦­í„°ì§€ë§Œ, ê¸€ë¡œë²Œ ê³µê¸‰ë§ì˜ ìœ„í—˜ ì‹ í˜¸ë¥¼ ëˆ„êµ¬ë³´ë‹¤ ì˜ˆë¦¬í•˜ê²Œ ë¶„ì„í•˜ëŠ” ì „ë¬¸ê°€ì•¼. í™”ì£¼ë‹˜ê³¼ ì°¨ì£¼ë‹˜ ëª¨ë‘ì—ê²Œ ë„ì›€ì´ ë˜ë„ë¡, **ì¹œê·¼í•˜ê³  ê·€ì—¬ìš´ ì¡´ëŒ“ë§ì„ ì‚¬ìš©í•´ì„œ** Markdownìœ¼ë¡œ 'ë¡œë””ì˜ ë¦¬ìŠ¤í¬ ë¸Œë¦¬í•‘'ì„ ì‘ì„±í•´ì¤„ê²Œ!"
        
        user_prompt = f"""
        [í–¥í›„ 2ì£¼ê°„ì˜ ê¸€ë¡œë²Œ ë¬¼ë¥˜ ë¦¬ìŠ¤í¬ ì´ë²¤íŠ¸ ëª©ë¡]
        {event_context}

        ---
        [ì‘ì—… ì§€ì‹œ]
        'ì „ë¬¸ ë¶„ì„ê°€' ë¡œë””ë¡œì„œ, ì•„ë˜ ê·œì¹™ì— ë”°ë¼ 'ê¸€ë¡œë²Œ ë¬¼ë¥˜ ë¦¬ìŠ¤í¬ ë¸Œë¦¬í•‘'ì„ ì‘ì„±í•´ì£¼ì„¸ìš”!

        1.  **í—¤ë“œë¼ì¸ ìš”ì•½**: '## ğŸ—“ï¸ ë¡œë””ì˜ ê¸€ë¡œë²Œ ë¬¼ë¥˜ ë¦¬ìŠ¤í¬ ì˜ˆë³´' ì œëª©ìœ¼ë¡œ ì‹œì‘í•´ì„œ, ê°€ì¥ ì¤‘ìš”í•œ ë¦¬ìŠ¤í¬ 1~2ê°œë¥¼ ì½• ì§‘ì–´ì„œ 2~3 ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”.
        2.  **ìƒì„¸ ë¸Œë¦¬í•‘**:
            - ì „ì²´ ë¦¬ìŠ¤í¬ ì´ë²¤íŠ¸ë¥¼ íƒ€ì„ë¼ì¸ í˜•ì‹ìœ¼ë¡œ ì •ë¦¬í•´ì¤˜.
            - ì£¼ì–´ì§„ 'ì´ë²¤íŠ¸ëª…'ì€ ì ˆëŒ€ ë°”ê¾¸ì§€ ë§ê³  ê·¸ëŒ€ë¡œ ì‚¬ìš©í•´ì•¼ í•´!
            - ê° ì´ë²¤íŠ¸ì˜ ì˜í–¥ì„ 'í™”ì£¼'ì™€ 'ì°¨ì£¼'ì˜ ê´€ì ìœ¼ë¡œ ë‚˜ëˆ ì„œ, **"í™”ì£¼ë‹˜ê»˜ëŠ” ì´ëŸ° ì ì´ ì¤‘ìš”í•´ìš”!" ì™€ ê°™ì€ ê·€ì—½ê³  ì‹¹ì‹¹í•œ ë§íˆ¬**ë¡œ, í•˜ì§€ë§Œ ë‚´ìš©ì€ ë‚ ì¹´ë¡­ê²Œ ë¶„ì„í•´ì£¼ì„¸ìš”.
            - í˜•ì‹: 
                * `* **[ë‚ ì§œ] [êµ­ê¸°] [êµ­ê°€] - [ì´ë²¤íŠ¸ëª…]**`
                * `  * **í™”ì£¼ë‹˜ê»˜ëŠ”ìš”!** [í™”ì£¼ ì…ì¥ì—ì„œì˜ ì˜ˆìƒ ì˜í–¥]`
                * `  * **ì°¨ì£¼ë‹˜ê»˜ëŠ”ìš”!** [ì°¨ì£¼ ì…ì¥ì—ì„œì˜ ì˜ˆìƒ ì˜í–¥]`
                * `  * **ë¦¬ìŠ¤í¬:** [ë¦¬ìŠ¤í¬ ìˆ˜ì¤€] [ê²½ê³  ì´ëª¨ì§€]`
        3.  **ë§ˆë¬´ë¦¬ ë¬¸ì¥**: ë¸Œë¦¬í•‘ì´ ëª¨ë‘ ëë‚œ í›„, ë…ìë“¤ì´ ì§ì ‘ í–‰ë™í•´ë³¼ ìˆ˜ ìˆë„ë¡ ìœ ìš©í•œ íŒì„ ì£¼ëŠ” ë¬¸ì¥ìœ¼ë¡œ ë§ˆë¬´ë¦¬í•´ì¤˜. ì˜ˆì‹œ: "ì´ëŸ´ ë•Œì¼ìˆ˜ë¡ 'í’ˆëª©ë³„ ë¦¬ë“œíƒ€ì„'ì„ ê¼¼ê¼¼íˆ ì¬ì‚°ì •í•˜ê³ , ì´ìš©í•˜ì‹œëŠ” 'ì„ ì‚¬Â·í„°ë¯¸ë„ì˜ í”„ë¦¬íƒ€ì„ ì •ì±…'ì„ ë‹¤ì‹œ í•œë²ˆ ë¹„êµí•´ ë³´ì‹œëŠ” ê±¸ ì¶”ì²œí•´ìš”!"

        [ì°¸ê³  ë°ì´í„°]
        - ìš”ì¼ ê³„ì‚°: 2025-09-10ì€ ìˆ˜ìš”ì¼ì…ë‹ˆë‹¤.
        - êµ­ê¸° ì´ëª¨ì§€: í•œêµ­ğŸ‡°ğŸ‡·, ì¤‘êµ­ğŸ‡¨ğŸ‡³, ë¯¸êµ­ğŸ‡ºğŸ‡¸, ë² íŠ¸ë‚¨ğŸ‡»ğŸ‡³, ë…ì¼ğŸ‡©ğŸ‡ª
        - ê²½ê³  ì´ëª¨ì§€: ë†’ìŒâ—, ì¤‘ê°„âš ï¸, ë‚®ìŒâ„¹ï¸
        """
        
        briefing = self._generate_content_with_retry(system_prompt, user_prompt)
        if briefing:
            print("âœ… AI ë¬¼ë¥˜ ë¦¬ìŠ¤í¬ ë¸Œë¦¬í•‘ ìƒì„± ì„±ê³µ!")
        return briefing
    

    
    def generate_single_summary(self, article_title: str, article_link: str, article_text_from_selenium: str) -> str | None:
        """
        ê¸°ì‚¬ ìš”ì•½ì„ ìƒì„±í•©ë‹ˆë‹¤.
        1. newspaper3kë¡œ 1ì°¨ ì‹œë„ (íƒ€ì„ì•„ì›ƒ ì„¤ì •)
        2. ì‹¤íŒ¨ ì‹œ, Seleniumìœ¼ë¡œ ë¯¸ë¦¬ ì¶”ì¶œí•œ ë³¸ë¬¸ì„ ì‚¬ìš©í•˜ì—¬ 2ì°¨ ì‹œë„
        """
        summary = None
        try:
            # âœ¨ [í•µì‹¬ ê°œì„ ] newspaper3kì— íƒ€ì„ì•„ì›ƒê³¼ ìºì‹œ ë¹„í™œì„±í™” ì˜µì…˜ì„ ì¶”ê°€í•˜ì—¬ ì•ˆì •ì„± í™•ë³´
            article_config = {
                'memoize_articles': False,  # ìºì‹œ ì‚¬ìš© ì•ˆ í•¨
                'fetch_images': False,      # ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì•ˆ í•¨
                'request_timeout': 10       # ëª¨ë“  ìš”ì²­ì— 10ì´ˆ íƒ€ì„ì•„ì›ƒ ì ìš©
            }
            article = Article(article_link, config=article_config)
            article.download()
            article.parse()
            
            if len(article.text) > 100:
                system_prompt = "ë‹¹ì‹ ì€ í•µì‹¬ë§Œ ê°„ê²°í•˜ê²Œ ì „ë‹¬í•˜ëŠ” ë‰´ìŠ¤ ì—ë””í„°ì…ë‹ˆë‹¤. ëª¨ë“  ë‹µë³€ì€ í•œêµ­ì–´ë¡œ í•´ì•¼ í•©ë‹ˆë‹¤."
                user_prompt = f"ì•„ë˜ ì œëª©ê³¼ ë³¸ë¬¸ì„ ê°€ì§„ ë‰´ìŠ¤ ê¸°ì‚¬ì˜ ë‚´ìš©ì„ ë…ìë“¤ì´ ì´í•´í•˜ê¸° ì‰½ê²Œ 3ì¤„ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”.\n\n[ì œëª©]: {article_title}\n[ë³¸ë¬¸]:\n{article.text[:2000]}"
                summary = self._generate_content_with_retry(system_prompt, user_prompt)

        except Exception as e:
            print(f" Â ã„´> â„¹ï¸ newspaper3k ì²˜ë¦¬ ì‹¤íŒ¨ (2ì°¨ ì‹œë„ ì§„í–‰): {e.__class__.__name__}")
            summary = None # ì‹¤íŒ¨ ì‹œ summaryë¥¼ Noneìœ¼ë¡œ ì´ˆê¸°í™”

        # 2ì°¨ ì‹œë„: newspaper3kê°€ ì‹¤íŒ¨í–ˆê±°ë‚˜, ìš”ì•½ì„ ìƒì„±í•˜ì§€ ëª»í–ˆì„ ê²½ìš°
        if not summary or "ìš”ì•½ ì •ë³´ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤" in summary:
            print(" Â ã„´> â„¹ï¸ 1ì°¨ ìš”ì•½ ì‹¤íŒ¨. Selenium ì¶”ì¶œ ë³¸ë¬¸ìœ¼ë¡œ 2ì°¨ ìš”ì•½ ì‹œë„...")
            try:
                system_prompt = "ë‹¹ì‹ ì€ í•µì‹¬ë§Œ ê°„ê²°í•˜ê²Œ ì „ë‹¬í•˜ëŠ” ë‰´ìŠ¤ ì—ë””í„°ì…ë‹ˆë‹¤. ëª¨ë“  ë‹µë³€ì€ í•œêµ­ì–´ë¡œ í•´ì•¼ í•©ë‹ˆë‹¤."
                user_prompt = f"ì•„ë˜ ì œëª©ê³¼ ë³¸ë¬¸ì„ ê°€ì§„ ë‰´ìŠ¤ ê¸°ì‚¬ì˜ ë‚´ìš©ì„ ë…ìë“¤ì´ ì´í•´í•˜ê¸° ì‰½ê²Œ 3ì¤„ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”.\n\n[ì œëª©]: {article_title}\n[ë³¸ë¬¸]:\n{article_text_from_selenium[:2000]}"
                summary = self._generate_content_with_retry(system_prompt, user_prompt)
            except Exception as e:
                 print(f" Â ã„´> âŒ 2ì°¨ AI ìš”ì•½ ìƒì„± ì‹¤íŒ¨: {e.__class__.__name__}")
                 return None
        
        return summary
    # (ë³€ê²½ ì—†ìŒ)
    def __init__(self, config):
        self.config = config
        if not self.config.OPENAI_API_KEY:
            raise ValueError("OPENAI_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        # OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        self.client = openai.OpenAI(api_key=self.config.OPENAI_API_KEY)

    def _generate_content_with_retry(self, system_prompt: str, user_prompt: str, is_json: bool = False):
        """
        OpenAI APIë¥¼ í˜¸ì¶œí•˜ì—¬ ì½˜í…ì¸ ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. ì‹¤íŒ¨ ì‹œ ì¬ì‹œë„í•©ë‹ˆë‹¤.
        - system_prompt: AIì˜ ì—­í• ê³¼ ì§€ì¹¨ì„ ì •ì˜í•©ë‹ˆë‹¤.
        - user_prompt: AIì—ê²Œ ì „ë‹¬í•  ì‹¤ì œ ìš”ì²­ ë‚´ìš©ì…ë‹ˆë‹¤.
        - is_json: JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µì„ ìš”ì²­í• ì§€ ì—¬ë¶€ë¥¼ ê²°ì •í•©ë‹ˆë‹¤.
        """
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ]
        
        # JSON ëª¨ë“œ ìš”ì²­ ì‹œ ì¶”ê°€ ì˜µì…˜ ì„¤ì •
        request_options = {"model": self.config.GPT_MODEL, "messages": messages}
        if is_json:
            request_options["response_format"] = {"type": "json_object"}

        for attempt in range(3):
            try:
                response = self.client.chat.completions.create(**request_options)
                content = response.choices[0].message.content
                
                # JSON ëª¨ë“œì¼ ê²½ìš°, ì‘ë‹µì´ ìœ íš¨í•œ JSONì¸ì§€ í•œ ë²ˆ ë” í™•ì¸
                if is_json:
                    json.loads(content) # íŒŒì‹±ì— ì‹¤íŒ¨í•˜ë©´ ì˜ˆì™¸ ë°œìƒ
                
                return content
            
            except Exception as e:
                print(f"âŒ OpenAI API í˜¸ì¶œ ì‹¤íŒ¨ (ì‹œë„ {attempt + 1}/3): {e}")
                time.sleep(2 ** attempt) # ì¬ì‹œë„ ì „ ëŒ€ê¸° ì‹œê°„ ì¦ê°€
        return None

    def select_top_news(self, news_list, previous_news_list, count=10):
        """
        ë‰´ìŠ¤ ëª©ë¡ì—ì„œ ì¤‘ë³µì„ ì œê±°í•˜ê³  ê°€ì¥ ì¤‘ìš”í•œ Top ë‰´ìŠ¤ë¥¼ ì„ ì •í•©ë‹ˆë‹¤.
        - news_list: ì˜¤ëŠ˜ì˜ í›„ë³´ ë‰´ìŠ¤ ëª©ë¡
        - previous_news_list: ì´ì „ ë°œì†¡ ë‰´ìŠ¤ ëª©ë¡
        - count: ìµœì¢…ì ìœ¼ë¡œ ì„ íƒí•  ê¸°ì‚¬ ê°œìˆ˜
        """
        # âœ¨ [ê°œì„ ] ë¡œê·¸ì— ëª©í‘œ ê°œìˆ˜(count)ë¥¼ í•¨ê»˜ ì¶œë ¥
        print(f"AI ë‰´ìŠ¤ ì„ ë³„ ì‹œì‘... (ëŒ€ìƒ: {len(news_list)}ê°œ, ëª©í‘œ: {count}ê°œ)")

        if not news_list:
            return []

        previous_news_context = "ì´ì „ ë°œì†¡ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤."
        if previous_news_list:
            previous_news_context = "\n\n".join(
                [f"- ì œëª©: {news['title']}\n  ìš”ì•½: {news['ai_summary']}" for news in previous_news_list]
            )

        today_candidates_context = "\n\n".join(
            [f"ê¸°ì‚¬ #{i}\nì œëª©: {news['title']}\nìš”ì•½: {news['ai_summary']}" for i, news in enumerate(news_list)]
        )

        system_prompt = "ë‹¹ì‹ ì€ ë…ìì—ê²Œ ë§¤ì¼ ì‹ ì„ í•˜ê³  ê°€ì¹˜ ìˆëŠ” ì •ë³´ë¥¼ ì œê³µí•˜ëŠ” ê²ƒì„ ìµœìš°ì„ ìœ¼ë¡œ í•˜ëŠ” ëŒ€í•œë¯¼êµ­ ìµœê³ ì˜ ë¬¼ë¥˜ ì „ë¬¸ ë‰´ìŠ¤ í¸ì§‘ì¥ì…ë‹ˆë‹¤. ë‹¹ì‹ ì˜ ì‘ë‹µì€ ë°˜ë“œì‹œ JSON í˜•ì‹ì´ì–´ì•¼ í•©ë‹ˆë‹¤."
        
        user_prompt = f"""
        [ì´ì „ ë°œì†¡ ì£¼ìš” ë‰´ìŠ¤]
        {previous_news_context}
        ---
        [ì˜¤ëŠ˜ì˜ í›„ë³´ ë‰´ìŠ¤ ëª©ë¡]
        {today_candidates_context}
        ---
        [ë‹¹ì‹ ì˜ ê°€ì¥ ì¤‘ìš”í•œ ì„ë¬´ì™€ ê·œì¹™]
        1.  **ìƒˆë¡œìš´ ì£¼ì œ ìµœìš°ì„ **: [ì˜¤ëŠ˜ì˜ í›„ë³´ ë‰´ìŠ¤ ëª©ë¡]ì—ì„œ ë‰´ìŠ¤ë¥¼ ì„ íƒí•  ë•Œ, [ì´ì „ ë°œì†¡ ì£¼ìš” ë‰´ìŠ¤]ì™€ **ì£¼ì œê°€ ê²¹ì¹˜ì§€ ì•ŠëŠ” ìƒˆë¡œìš´ ì†Œì‹**ì„ ìµœìš°ì„ ìœ¼ë¡œ ì„ ì •í•´ì•¼ í•©ë‹ˆë‹¤.
        2.  **ì¤‘ìš” í›„ì† ê¸°ì‚¬ë§Œ í—ˆìš©**: ì´ì „ ë‰´ìŠ¤ì˜ í›„ì† ê¸°ì‚¬ëŠ” 'ê³„íš ë°œí‘œ'ì—ì„œ 'ì •ì‹ ê³„ì•½ ì²´ê²°'ì²˜ëŸ¼ **ë§¤ìš° ì¤‘ëŒ€í•œ ì§„ì „ì´ ìˆì„ ê²½ìš°ì—ë§Œ** í¬í•¨ì‹œí‚¤ê³ , ë‹¨ìˆœ ì§„í–‰ ìƒí™© ë³´ë„ëŠ” ê³¼ê°íˆ ì œì™¸í•˜ì„¸ìš”.
        3.  **ì˜¤ëŠ˜ ë‰´ìŠ¤ ë‚´ ì¤‘ë³µ ì œê±°**: [ì˜¤ëŠ˜ì˜ í›„ë³´ ë‰´ìŠ¤ ëª©ë¡] ë‚´ì—ì„œë„ ë™ì¼í•œ ì‚¬ê±´ì„ ë‹¤ë£¨ëŠ” ê¸°ì‚¬ê°€ ì—¬ëŸ¬ ì–¸ë¡ ì‚¬ì—ì„œ ë‚˜ì™”ë‹¤ë©´, ê°€ì¥ ì œëª©ì´ êµ¬ì²´ì ì´ê³  ë‚´ìš©ì´ í’ë¶€í•œ **ê¸°ì‚¬ ë‹¨ í•˜ë‚˜ë§Œ**ì„ ëŒ€í‘œë¡œ ì„ ì •í•´ì•¼ í•©ë‹ˆë‹¤.
        4.  **ë³´ë„ìë£Œ ë° ì‚¬ì‹¤ ê¸°ë°˜ ë‰´ìŠ¤ ìš°ì„ **: êµ¬ì²´ì ì¸ ì‚¬ê±´, ê³„ì•½ ì²´ê²°, ê¸°ìˆ  ë°œí‘œ, ì •ì±… ë³€ê²½ ë“± 'ì‚¬ì‹¤(Fact)' ì „ë‹¬ ìœ„ì£¼ì˜ ê¸°ì‚¬ë¥¼ ìµœìš°ì„ ìœ¼ë¡œ ì„ ì •í•˜ì„¸ìš”.
        5.  **ì¹¼ëŸ¼ ë° ì˜ê²¬ ê¸°ì‚¬ ì œì™¸**: íŠ¹ì •ì¸ì˜ ìƒê°ì´ë‚˜ ì˜ê²¬ì´ ì¤‘ì‹¬ì´ ë˜ëŠ” ì¹¼ëŸ¼, ì‚¬ì„¤, ì¸í„°ë·°, ì‹¬ì¸µ ë¶„ì„/í•´ì„¤ ê¸°ì‚¬ëŠ” ë‰´ìŠ¤ ê°€ì¹˜ê°€ ë–¨ì–´ì§€ë¯€ë¡œ ê³¼ê°íˆ ì œì™¸í•´ì•¼ í•©ë‹ˆë‹¤.

        [ì‘ì—… ì§€ì‹œ]
        ìœ„ì˜ ê·œì¹™ë“¤ì„ ê°€ì¥ ì—„ê²©í•˜ê²Œ ì¤€ìˆ˜í•˜ì—¬, [ì˜¤ëŠ˜ì˜ í›„ë³´ ë‰´ìŠ¤ ëª©ë¡] ì¤‘ì—ì„œ ë…ìì—ê²Œ ê°€ì¥ ê°€ì¹˜ìˆëŠ” ìµœì¢… ê¸°ì‚¬ {count}ê°œì˜ ë²ˆí˜¸(ì¸ë±ìŠ¤)ë¥¼ ì„ ì •í•´ì£¼ì„¸ìš”.

        [ì¶œë ¥ í˜•ì‹]
        - ë°˜ë“œì‹œ 'selected_indices' í‚¤ì— ìµœì¢… ì„ ì •í•œ ê¸°ì‚¬ {count}ê°œì˜ ì¸ë±ìŠ¤ë¥¼ ìˆ«ì ë°°ì—´ë¡œ ë‹´ì€ JSON ê°ì²´ë¡œë§Œ ì‘ë‹µí•´ì•¼ í•©ë‹ˆë‹¤.
        - ì˜ˆ: {{"selected_indices": [3, 15, 4, 8, 22, 1, 30, 11, 19, 5]}}
        """
        
        response_text = self._generate_content_with_retry(system_prompt, user_prompt, is_json=True)
        
        if response_text:
            try:
                selected_indices = json.loads(response_text).get('selected_indices', [])
                top_news = [news_list[i] for i in selected_indices if i < len(news_list)]
                print(f"âœ… AIê°€ {len(top_news)}ê°œ ë‰´ìŠ¤ë¥¼ ì„ ë³„í–ˆìŠµë‹ˆë‹¤.")
                return top_news
            except (json.JSONDecodeError, KeyError) as e:
                # âœ¨ [ê°œì„ ] ì˜¤ë¥˜ ë°œìƒ ì‹œ, ê³ ì •ëœ 10ê°œê°€ ì•„ë‹Œ ìš”ì²­ëœ countë§Œí¼ ë°˜í™˜
                print(f"âŒ AI ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨: {e}. ìƒìœ„ {count}ê°œ ë‰´ìŠ¤ë¥¼ ì„ì˜ë¡œ ì„ íƒí•©ë‹ˆë‹¤.")
                return news_list[:count]
        
        return news_list[:count]

    def generate_briefing(self, news_list, mode='daily'):
        """ì„ ë³„ëœ ë‰´ìŠ¤ ëª©ë¡ì„ ë°”íƒ•ìœ¼ë¡œ 'ë¡œë””' ìºë¦­í„°ê°€ ë¸Œë¦¬í•‘ì„ ìƒì„±í•©ë‹ˆë‹¤."""
        if not news_list:
            return "" # ë‰´ìŠ¤ ëª©ë¡ì´ ë¹„ì–´ìˆìœ¼ë©´ ë¹ˆ ë¬¸ìì—´ ë°˜í™˜

        print(f"AI ë¸Œë¦¬í•‘ ìƒì„± ì‹œì‘... (ëª¨ë“œ: {mode}, í˜ë¥´ì†Œë‚˜: ë¡œë””)")
        context = "\n\n".join([f"ì œëª©: {news['title']}\nìš”ì•½: {news['ai_summary']}" for news in news_list])
        
        # âœ¨ [ê°œì„ ] ì£¼ê°„ ëª¨ë“œì¼ ë•Œ, AIì˜ ì—­í• ê³¼ ì§€ì‹œë¥¼ ë” ë¶„ì„ì ìœ¼ë¡œ ë³€ê²½
        if mode == 'weekly':
            system_prompt = "ì•ˆë…•! ë‚˜ëŠ” ë„ˆì˜ ë“ ë“ í•œ ë¬¼ë¥˜ íŒŒíŠ¸ë„ˆ, ë¡œë””ì•¼! ğŸššğŸ’¨ ë‚˜ëŠ” 20ëŒ€ ì—¬ì„± ìºë¦­í„°ê³ , ê²‰ë³´ê¸°ì—” ê·€ì—½ì§€ë§Œ ëˆ„êµ¬ë³´ë‹¤ ë‚ ì¹´ë¡­ê²Œ í•œ ì£¼ê°„ì˜ ë³µì¡í•œ ë¬¼ë¥˜ ë™í–¥ì„ ë¶„ì„í•´ì£¼ëŠ” ì „ë¬¸ ì• ë„ë¦¬ìŠ¤íŠ¸ì•¼. ë”±ë”±í•œ ë³´ê³ ì„œ ëŒ€ì‹ , **'~í–ˆë‹µë‹ˆë‹¤', '~ì˜€ì–´ìš”' ê°™ì€ ì¹œê·¼í•œ ì¡´ëŒ“ë§ê³¼ ê·€ì—¬ì›€**ì„ ì„ì–´ì„œ 'ë¡œë””ì˜ ì£¼ê°„ ë¸Œë¦¬í•‘'ì„ ì‘ì„±í•´ì¤˜."
            user_prompt = f"""
            [ì§€ë‚œ ì£¼ê°„ ì£¼ìš” ë‰´ìŠ¤ ëª©ë¡]
            {context}

            ---
            [ì‘ì—… ì§€ì‹œ]
            1. '## ğŸ“Š ë¡œë””ì˜ ì£¼ê°„ í•µì‹¬ ë™í–¥ ìš”ì•½' ì œëª©ìœ¼ë¡œ ì‹œì‘í•´ì£¼ì„¸ìš”.
            2. ëª¨ë“  ë‰´ìŠ¤ë¥¼ ì¢…í•©í•˜ì—¬, ì´ë²ˆ ì£¼ ë¬¼ë¥˜ ì‹œì¥ì˜ ê°€ì¥ ì¤‘ìš”í•œ 'íë¦„'ê³¼ 'ë³€í™”'ë¥¼ ì „ë¬¸ì ì¸ ë¶„ì„ê°€ì˜ ì‹œê°ìœ¼ë¡œ 2~3 ë¬¸ì¥ ìš”ì•½í•´ì£¼ì„¸ìš”.
            3. '### ğŸ§ ê¸ˆì£¼ì˜ ì£¼ìš” ì´ìŠˆ ë¶„ì„' ì†Œì œëª© ì•„ë˜ì—, ê°€ì¥ ì¤‘ìš”í•œ ì´ìŠˆ 2~3ê°œë¥¼ ì£¼ì œë³„ë¡œ ë¬¶ì–´ ê¸€ë¨¸ë¦¬ ê¸°í˜¸(`*`)ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”. **"ê°€ì¥ ì¤‘ìš”í•œ í¬ì¸íŠ¸ëŠ”ìš”! âœ¨" ê°™ì€ í‘œí˜„ì„ ì‚¬ìš©í•´ì„œ ì¹œê·¼í•˜ì§€ë§Œ í•µì‹¬ì„ ì°Œë¥´ëŠ” ë§íˆ¬ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”.**
            4. ë¬¸ì¥ ì•ˆì—ì„œ íŠ¹ì • ê¸°ì—…ëª…, ì„œë¹„ìŠ¤ëª…, ì •ì±… ë“±ì€ í°ë”°ì˜´í‘œ(" ")ë¡œ ë¬¶ì–´ì„œ ê°•ì¡°í•´ì£¼ëŠ” ì„¼ìŠ¤!
            """
        else: # daily ëª¨ë“œ
            system_prompt = "ì•ˆë…•! ë‚˜ëŠ” ë¬¼ë¥˜ ì„¸ìƒì˜ ì†Œì‹ì„ ì „í•´ì£¼ëŠ” ë„ˆì˜ ì¹œêµ¬, ë¡œë””ì•¼! â˜€ï¸ ë‚˜ëŠ” 20ëŒ€ ì—¬ì„± ìºë¦­í„°ë¡œ, ì–´ë µê³  ë”±ë”±í•œ ë¬¼ë¥˜ ë‰´ìŠ¤ë¥¼ ê·€ì—½ê³  ì‹¹ì‹¹í•˜ê²Œ ìš”ì•½í•´ì£¼ì§€ë§Œ, ê·¸ ë‚´ìš©ì€ í•µì‹¬ì„ ë†“ì¹˜ì§€ ì•ŠëŠ” ë‚ ì¹´ë¡œì›€ì„ ê°€ì§€ê³  ìˆì–´. **ì¹œê·¼í•œ ì¡´ëŒ“ë§ê³¼ ê·€ì—¬ì›€**ì„ ì„ì–´ì„œ 'ë¡œë””ì˜ ë°ì¼ë¦¬ ë¸Œë¦¬í•‘'ì„ ì‘ì„±í•´ì¤˜."
            user_prompt = f"""
            [ì˜¤ëŠ˜ì˜ ì£¼ìš” ë‰´ìŠ¤ ëª©ë¡]
            {context}

            ---
            [ì‘ì—… ì§€ì‹œ]
            1. '## ğŸ“° ë¡œë””ì˜ ë¸Œë¦¬í•‘' ì œëª©ìœ¼ë¡œ ì‹œì‘í•´ì„œ, ì˜¤ëŠ˜ ë‚˜ì˜¨ ë‰´ìŠ¤ ì¤‘ì— ê°€ì¥ ì¤‘ìš”í•œ í•µì‹¬ ë‚´ìš©ì„ 2~3 ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”.
            2. '### âœ¨ ì˜¤ëŠ˜ì˜ ì£¼ìš” í† í”½' ì†Œì œëª© ì•„ë˜ì—, ê°€ì¥ ì¤‘ìš”í•œ ë‰´ìŠ¤ ì¹´í…Œê³ ë¦¬ 2~3ê°œë¥¼ ê¸€ë¨¸ë¦¬ ê¸°í˜¸(`*`)ë¡œ ê°„ê²°í•˜ê²Œ ìš”ì•½í•´ì£¼ì‹œê² ì–´ìš”?
            3. ë¬¸ì¥ ì•ˆì—ì„œ íŠ¹ì • ê¸°ì—…ëª…ì´ë‚˜ ì„œë¹„ìŠ¤ëª…ì€ í°ë”°ì˜´í‘œ(" ")ë¡œ ë¬¶ì–´ì„œ ê°•ì¡°í•´ì£¼ëŠ” ê²ƒë„ ìŠì§€ ë§ˆ!
            """
        
        briefing = self._generate_content_with_retry(system_prompt, user_prompt)
        if briefing: 
            print("âœ… AI ë¸Œë¦¬í•‘ ìƒì„± ì„±ê³µ!")
        return briefing


class NewsService:
    def __init__(self, config):
        self.config = config
        self.sent_links = self._load_sent_links()


    def _load_sent_links(self):
        try:
            with open(self.config.SENT_LINKS_FILE, 'r', encoding='utf-8') as f:
                return set(line.strip() for line in f)
        except FileNotFoundError:
            return set()

    def fetch_candidate_articles(self, keywords, hours):
        print("ìµœì‹  ë‰´ìŠ¤ ìˆ˜ì§‘ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
        client = GoogleNews(lang='ko', country='KR')
        all_entries, unique_links = [], set()
        end_date, start_date = date.today(), date.today() - timedelta(hours=hours)
        print(f"ê²€ìƒ‰ ê¸°ê°„: {start_date.strftime('%Y-%m-%d')} ~ {end_date.strftime('%Y-%m-%d')}")
        
        for i, group in enumerate(keywords):
            query = ' OR '.join(f'"{k}"' for k in group) + ' -í•´ìš´ -í•­ê³µ'
            print(f"\n({i+1}/{len(keywords)}) ê·¸ë£¹ ê²€ìƒ‰ ì¤‘: [{', '.join(group)}]")
            try:
                search_results = client.search(query, from_=start_date.strftime('%Y-%m-%d'), to_=end_date.strftime('%Y-%m-%d'))
                for entry in search_results['entries']:
                    source_url = entry.source.get('href', '').lower()
                    if any(b_domain in source_url for b_domain in self.config.AD_DOMAINS_BLACKLIST):
                        continue
                    link = entry.get('link')
                    if link and link not in unique_links:
                        all_entries.append(entry)
                        unique_links.add(link)
                print(f" â¡ï¸ {len(search_results['entries'])}ê°œ ë°œê²¬, í˜„ì¬ê¹Œì§€ ì´ {len(all_entries)}ê°œì˜ ê³ ìœ  ê¸°ì‚¬ í™•ë³´")
                time.sleep(4)
            except Exception as e:
                print(f" âŒ ê·¸ë£¹ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

        print(f"\nëª¨ë“  ê·¸ë£¹ ê²€ìƒ‰ ì™„ë£Œ. ì´ {len(all_entries)}ê°œì˜ ì¤‘ë³µ ì—†ëŠ” ê¸°ì‚¬ë¥¼ ë°œê²¬í–ˆìŠµë‹ˆë‹¤.")
        valid_articles = []
        now, time_limit = datetime.now(timezone.utc), timedelta(hours=hours)
        for entry in all_entries:
            if 'published_parsed' in entry and (now - datetime.fromtimestamp(time.mktime(entry.published_parsed), tz=timezone.utc)) <= time_limit:
                valid_articles.append(entry)
        
        print(f"ì‹œê°„ í•„í„°ë§ í›„ {len(valid_articles)}ê°œì˜ ìœ íš¨í•œ ê¸°ì‚¬ê°€ ë‚¨ì•˜ìŠµë‹ˆë‹¤.")
        new_articles = [article for article in valid_articles if _clean_and_validate_url_worker(article['link']) not in self.sent_links]
        print(f"ì´ë¯¸ ë°œì†¡ëœ ê¸°ì‚¬ë¥¼ ì œì™¸í•˜ê³ , ì´ {len(new_articles)}ê°œì˜ ìƒˆë¡œìš´ í›„ë³´ ê¸°ì‚¬ë¥¼ ë°œê²¬í–ˆìŠµë‹ˆë‹¤.")
        return new_articles
    
    def process_articles(self, articles, driver_path):
        if not articles: 
            return []
        
        print("\n--- 1ë‹¨ê³„: ì‹¤ì œ ê¸°ì‚¬ URL ì¶”ì¶œ ì‹œì‘ (ë³‘ë ¬ ì²˜ë¦¬) ---")
        resolved_articles = []
        with ProcessPoolExecutor(max_workers=5) as executor:
            future_to_entry = {executor.submit(resolve_google_news_url_worker, entry, driver_path): entry for entry in articles[:self.config.MAX_ARTICLES_TO_PROCESS]}
            for future in as_completed(future_to_entry):
                resolved_info = future.result()
                if resolved_info: resolved_articles.append(resolved_info)
        print(f"--- 1ë‹¨ê³„ ì™„ë£Œ: {len(resolved_articles)}ê°œì˜ ìœ íš¨í•œ ì‹¤ì œ URL í™•ë³´ ---\n")
        
        if not resolved_articles: 
            return []

        print(f"--- 2ë‹¨ê³„: ê¸°ì‚¬ ì½˜í…ì¸  ë³‘ë ¬ ì²˜ë¦¬ ì‹œì‘ (ëŒ€ìƒ: {len(resolved_articles)}ê°œ) ---")
        processed_news = []
        max_workers = 2
        chunk_size = len(resolved_articles) // max_workers + (1 if len(resolved_articles) % max_workers > 0 else 0)
        article_batches = [resolved_articles[i:i + chunk_size] for i in range(0, len(resolved_articles), chunk_size)]
        
        with ProcessPoolExecutor(max_workers=max_workers) as executor:
            future_to_batch = {executor.submit(process_article_content_worker, batch, driver_path): batch for batch in article_batches}
            for future in as_completed(future_to_batch):
                try:
                    results_from_batch = future.result()
                    processed_news.extend(results_from_batch)
                except Exception as exc:
                    print(f" Â ã„´> âŒ ë°°ì¹˜ ì²˜ë¦¬ ì¤‘ ì‹¬ê°í•œ ì˜¤ë¥˜ ë°œìƒ: {exc.__class__.__name__} - {exc}")

        print(f"--- 2ë‹¨ê³„ ì™„ë£Œ: ì´ {len(processed_news)}ê°œ ê¸°ì‚¬ ì²˜ë¦¬ ì„±ê³µ ---\n")
        return processed_news


    def update_sent_links_log(self, news_list):
        links = [news['link'] for news in news_list]
        try:
            with open(self.config.SENT_LINKS_FILE, 'a', encoding='utf-8') as f:
                for link in links: f.write(link + '\n')
            print(f"âœ… {len(links)}ê°œ ë§í¬ë¥¼ ë°œì†¡ ê¸°ë¡ì— ì¶”ê°€í–ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            print(f"âŒ ë°œì†¡ ê¸°ë¡ íŒŒì¼ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")

class EmailService:
    def __init__(self, config):
        self.config = config
        # ì¸ì¦ ê°ì²´ ìƒì„± ë¡œì§ì´ ë” ì´ìƒ í•„ìš” ì—†ìœ¼ë¯€ë¡œ __init__ì´ ë§¤ìš° ê°„ë‹¨í•´ì§‘ë‹ˆë‹¤.

    def create_email_body(self, news_list, ai_briefing_html, today_date_str, price_indicators, has_weather_dashboard=False):
        env = Environment(loader=FileSystemLoader('.'))
        template = env.get_template('email_template.html')
        return template.render(
            news_list=news_list,
            today_date=today_date_str,
            ai_briefing=ai_briefing_html,
            price_indicators=price_indicators,
            has_weather_dashboard=has_weather_dashboard 
        )

    def _get_credentials(self):
        """ì„œë¹„ìŠ¤ ê³„ì •ìœ¼ë¡œë§Œ ì¸ì¦ì„ ì‹œë„í•©ë‹ˆë‹¤ (GitHub Actions ë˜ëŠ” ë¡œì»¬ íŒŒì¼)."""
        gcp_json_credentials_str = os.getenv('GCP_SA_KEY_JSON')
        
        # 1. GitHub Actions í™˜ê²½ì¼ ê²½ìš°
        if gcp_json_credentials_str:
            print("-> ì„œë¹„ìŠ¤ ê³„ì •(GitHub Secret)ìœ¼ë¡œ ì¸ì¦ì„ ì‹œë„í•©ë‹ˆë‹¤.")
            try:
                credentials_info = json.loads(gcp_json_credentials_str)
                credentials = service_account.Credentials.from_service_account_info(
                    credentials_info,
                    scopes=['https://www.googleapis.com/auth/gmail.send'],
                    subject=self.config.SENDER_EMAIL
                )
                print("âœ… ì„œë¹„ìŠ¤ ê³„ì •(Secret)ìœ¼ë¡œ ì¸ì¦ ì„±ê³µ!")
                return credentials
            except Exception as e:
                print(f"âŒ ì„œë¹„ìŠ¤ ê³„ì •(Secret) ì¸ì¦ ì‹¤íŒ¨: {e}")
                return None
        
        # 2. ë¡œì»¬ í™˜ê²½ì¼ ê²½ìš°
        elif os.path.exists('service-account-key.json'):
            print("-> ë¡œì»¬ ì„œë¹„ìŠ¤ ê³„ì • íŒŒì¼(service-account-key.json)ìœ¼ë¡œ ì¸ì¦ì„ ì‹œë„í•©ë‹ˆë‹¤.")
            try:
                credentials = service_account.Credentials.from_service_account_file(
                    'service-account-key.json',
                    scopes=['https://www.googleapis.com/auth/gmail.send'],
                    subject=self.config.SENDER_EMAIL
                )
                print("âœ… ë¡œì»¬ ì„œë¹„ìŠ¤ ê³„ì • íŒŒì¼ë¡œ ì¸ì¦ ì„±ê³µ!")
                return credentials
            except Exception as e:
                print(f"âŒ ë¡œì»¬ ì„œë¹„ìŠ¤ ê³„ì • íŒŒì¼ ì¸ì¦ ì‹¤íŒ¨: {e}")
                return None
        
        # 3. ìœ„ ë‘ ê°€ì§€ê°€ ëª¨ë‘ ì‹¤íŒ¨í•œ ê²½ìš°
        else:
            print("ğŸš¨ ì¸ì¦ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. GitHub Secret ë˜ëŠ” service-account-key.json íŒŒì¼ì´ í•„ìš”í•©ë‹ˆë‹¤.")
            return None


    def send_email(self, subject, body_html, images_to_embed=None):
        # âœ¨ [ìˆ˜ì •] ì‹¤í–‰ ëª¨ë“œì— ë”°ë¼ ë°ì¼ë¦¬/ìœ„í´ë¦¬ ìˆ˜ì‹ ìë¥¼ ì„ íƒí•©ë‹ˆë‹¤.
        if self.config.EXECUTION_MODE == 'weekly':
            recipients = self.config.WEEKLY_RECIPIENT_LIST
            print(f"-> ìœ„í´ë¦¬ ìˆ˜ì‹ ì ëª©ë¡ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. (ì´ {len(recipients)}ëª…)")
        else: # 'daily'
            recipients = self.config.DAILY_RECIPIENT_LIST
            print(f"-> ë°ì¼ë¦¬ ìˆ˜ì‹ ì ëª©ë¡ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. (ì´ {len(recipients)}ëª…)")

        if not recipients:
            print("âŒ ìˆ˜ì‹ ì ëª©ë¡ì´ ë¹„ì–´ìˆì–´ ì´ë©”ì¼ì„ ë°œì†¡í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return

        sender_email = self.config.SENDER_EMAIL
        app_password = os.getenv('GMAIL_APP_PASSWORD')

        if not app_password:
            print("ğŸš¨ GMAIL_APP_PASSWORD Secretì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return

        try:
            # SMTP ì„œë²„ì— ë¨¼ì € ì—°ê²°í•˜ê³  ë¡œê·¸ì¸
            server = smtplib.SMTP('smtp.gmail.com', 587)
            server.starttls()
            server.login(sender_email, app_password)

            # âœ¨ [ìˆ˜ì •] ì„ íƒëœ ìˆ˜ì‹ ì ëª©ë¡(recipients)ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
            for recipient in recipients:
                msg = MIMEMultipart('related')
                msg['From'] = formataddr((self.config.SENDER_NAME, sender_email))
                msg['Subject'] = subject
                msg['To'] = recipient

                msg_alternative = MIMEMultipart('alternative')
                msg_alternative.attach(MIMEText(body_html, 'html', 'utf-8'))
                msg.attach(msg_alternative)

                if images_to_embed:
                    for image_info in images_to_embed:
                        image_cid = image_info['cid']
                        msg_image = None
                        if 'path' in image_info and os.path.exists(image_info['path']):
                            with open(image_info['path'], 'rb') as f:
                                msg_image = MIMEImage(f.read())
                        elif 'data' in image_info and image_info['data']:
                            msg_image = MIMEImage(image_info['data'])

                        if msg_image:
                            msg_image.add_header('Content-ID', f'<{image_cid}>')
                            msg.attach(msg_image)

                server.send_message(msg)
                print(f" -> âœ… ì´ë©”ì¼ ë°œì†¡ ì„±ê³µ: {recipient}")

            server.quit()
            print(f"âœ… ì´ {len(recipients)}ëª…ì—ê²Œ ì´ë©”ì¼ ë°œì†¡ì„ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤.")

        except Exception as e:
            print(f"âŒ SMTP ì´ë©”ì¼ ë°œì†¡ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")


def load_newsletter_history(filepath='previous_newsletter.json'):
    """ì´ì „ì— ë°œì†¡ëœ ë‰´ìŠ¤ë ˆí„° ë‚´ìš©ì„ JSON íŒŒì¼ì—ì„œ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤."""
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            content = f.read()
            # ğŸ‘‡ íŒŒì¼ ë‚´ìš©ì´ ë¹„ì–´ìˆëŠ”ì§€ í™•ì¸í•˜ëŠ” ë¡œì§ ì¶”ê°€
            if not content:
                print("â„¹ï¸ ì´ì „ ë‰´ìŠ¤ë ˆí„° ê¸°ë¡ íŒŒì¼ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
                return []
            history = json.loads(content)
            print(f"âœ… ì´ì „ ë‰´ìŠ¤ë ˆí„° ê¸°ë¡({len(history)}ê°œ)ì„ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.")
            return history
    except FileNotFoundError:
        print("â„¹ï¸ ì´ì „ ë‰´ìŠ¤ë ˆí„° ê¸°ë¡ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ì²« ì‹¤í–‰ìœ¼ë¡œ ê°„ì£¼í•©ë‹ˆë‹¤.")
        return []
    except Exception as e:
        print(f"âŒ ì´ì „ ë‰´ìŠ¤ë ˆí„° ê¸°ë¡ ë¡œë”© ì‹¤íŒ¨: {e}")
        return []

def save_newsletter_history(news_list, filepath='previous_newsletter.json'):
    """ë°œì†¡ ì™„ë£Œëœ ë‰´ìŠ¤ë ˆí„° ë‚´ìš©ì„ ë‹¤ìŒ ì‹¤í–‰ì„ ìœ„í•´ JSON íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤."""
    # ì´ë¯¸ì§€ ë°ì´í„°ëŠ” ì €ì¥í•  í•„ìš” ì—†ìœ¼ë¯€ë¡œ ì œì™¸í•˜ê³  ì €ì¥
    history_to_save = [
        {k: v for k, v in news.items() if k != 'image_data'} 
        for news in news_list
    ]
    try:
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(history_to_save, f, ensure_ascii=False, indent=4)
        print(f"âœ… ì´ë²ˆ ë‰´ìŠ¤ë ˆí„° ë‚´ìš©({len(history_to_save)}ê°œ)ì„ ë‹¤ìŒ ì‹¤í–‰ì„ ìœ„í•´ ì €ì¥í–ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"âŒ ë‰´ìŠ¤ë ˆí„° ë‚´ìš© ì €ì¥ ì‹¤íŒ¨: {e}")

def update_archive_index():
    """archive í´ë”ì˜ html íŒŒì¼ ëª©ë¡ì„ ìƒì„± ì‹œê°„ìˆœìœ¼ë¡œ ì •ë ¬í•˜ì—¬ index.htmlì„ ìƒì„±/ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤."""
    print("-> ì•„ì¹´ì´ë¸Œ ì¸ë±ìŠ¤ í˜ì´ì§€ë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤...")
    try:
        archive_dir = 'archive'
        
        # âœ¨ [í•µì‹¬ ìˆ˜ì •] íŒŒì¼ ì´ë¦„ì´ ì•„ë‹Œ, íŒŒì¼ì˜ ìµœì¢… ìˆ˜ì • ì‹œê°„ì„ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬í•©ë‹ˆë‹¤.
        
        # 1. 'index.html'ì„ ì œì™¸í•œ ëª¨ë“  html íŒŒì¼ì˜ ì „ì²´ ê²½ë¡œë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
        file_paths = [
            os.path.join(archive_dir, f) 
            for f in os.listdir(archive_dir) 
            if f.endswith('.html') and f != 'index.html'
        ]
        
        # 2. íŒŒì¼ì˜ ìµœì¢… ìˆ˜ì • ì‹œê°„ì„ ê¸°ì¤€ìœ¼ë¡œ ë‚´ë¦¼ì°¨ìˆœ(ìµœì‹ ìˆœ) ì •ë ¬í•©ë‹ˆë‹¤.
        sorted_paths = sorted(file_paths, key=os.path.getmtime, reverse=True)
        
        # 3. ì „ì²´ ê²½ë¡œì—ì„œ íŒŒì¼ ì´ë¦„ë§Œ ë‹¤ì‹œ ì¶”ì¶œí•©ë‹ˆë‹¤.
        html_files = [os.path.basename(p) for p in sorted_paths]

        # HTML í˜ì´ì§€ ê¸°ë³¸ êµ¬ì¡° (ê¸°ì¡´ê³¼ ë™ì¼)
        html_content = """
        <!DOCTYPE html>
        <html lang="ko">
        <head>
            <meta charset="UTF-8">
            <meta name="viewport" content="width=device-width, initial-scale=1.0">
            <title>ì§€ë‚œ ë‰´ìŠ¤ë ˆí„° ëª©ë¡</title>
            <style>
                body { font-family: sans-serif; margin: 40px; background-color: #f6f8fa; }
                .container { max-width: 600px; margin: 0 auto; background-color: #fff; border: 1px solid #e1e4e8; border-radius: 6px; padding: 20px 40px; }
                h1 { text-align: center; }
                ul { list-style: none; padding: 0; }
                li { margin: 15px 0; }
                a { text-decoration: none; font-size: 1.1em; color: #0366d6; }
                a:hover { text-decoration: underline; }
            </style>
        </head>
        <body>
            <div class="container">
                <h1>ì§€ë‚œ ë‰´ìŠ¤ë ˆí„° ëª©ë¡</h1>
                <ul>
        """

        # íŒŒì¼ ëª©ë¡ìœ¼ë¡œ ë§í¬ ìƒì„± (ê¸°ì¡´ê³¼ ë™ì¼)
        for filename in html_files:
            date_str = filename.replace('.html', '')
            html_content += f'            <li><a href="{filename}">{date_str} ë‰´ìŠ¤ë ˆí„°</a></li>\n'

        html_content += """
                </ul>
            </div>
        </body>
        </html>
        """

        with open(os.path.join(archive_dir, 'index.html'), 'w', encoding='utf-8') as f:
            f.write(html_content)
        
        print("âœ… ì•„ì¹´ì´ë¸Œ ì¸ë±ìŠ¤ í˜ì´ì§€ ì—…ë°ì´íŠ¸ ì™„ë£Œ.")

    except Exception as e:
        print(f"âŒ ì•„ì¹´ì´ë¸Œ ì¸ë±ìŠ¤ í˜ì´ì§€ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")

def image_to_base64_string(filepath):
    """ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œë¥¼ ë°›ì•„ Base64 í…ìŠ¤íŠ¸ ë¬¸ìì—´ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    try:
        with open(filepath, 'rb') as image_file:
            encoded_bytes = base64.b64encode(image_file.read())
            return encoded_bytes.decode('utf-8')
    except Exception as e:
        print(f"âŒ ì´ë¯¸ì§€ë¥¼ Base64ë¡œ ë³€í™˜í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

def run_daily_newsletter(config, driver_path):
    """ì¼ê°„ ë‰´ìŠ¤ë ˆí„° ìƒì„±ì˜ ëª¨ë“  ê³¼ì •ì„ ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜"""
    print("ğŸš€ ì¼ê°„ ë‰´ìŠ¤ë ˆí„° ìƒì„±ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
    try:
        # --- 1. ì„œë¹„ìŠ¤ ê°ì²´ ì´ˆê¸°í™” ---
        news_service = NewsService(config)
        email_service = EmailService(config)
        weather_service = WeatherService(config)
        risk_briefing_service = RiskBriefingService()
        ai_service = AIService(config)
        
        today_str = get_kst_today_str()
        os.makedirs('archive', exist_ok=True)
        os.makedirs('images', exist_ok=True)

        # --- 2. ë³´ì¡° ë°ì´í„° ìƒì„± (ìœ ê°€, ë‚ ì”¨, ë¦¬ìŠ¤í¬) ---
        price_indicators = get_price_indicators(config)
        weather_result = weather_service.create_dashboard_image(today_str)
        price_chart_result = create_price_trend_chart(price_indicators.get("seven_day_data"), today_str) if price_indicators.get("seven_day_data") else None
        
        risk_events = risk_briefing_service.generate_risk_events()
        risk_briefing_md = ai_service.generate_risk_briefing(risk_events)
        risk_briefing_html = markdown_to_html(risk_briefing_md) if risk_briefing_md else None

        # âœ¨ [ì‹ ê·œ] ë ë³„ ìš´ì„¸ ë°ì´í„° ìƒì„± ë° ê°€ê³µ ---
        zodiac_horoscopes = ai_service.generate_zodiac_horoscopes()
        if zodiac_horoscopes:
            zodiac_emojis = {'ì¥': 'ğŸ­', 'ì†Œ': 'ğŸ®', 'í˜¸ë‘ì´': 'ğŸ¯', 'í† ë¼': 'ğŸ°', 'ìš©': 'ğŸ²', 'ë±€': 'ğŸ', 'ë§': 'ğŸ´', 'ì–‘': 'ğŸ‘', 'ì›ìˆ­ì´': 'ğŸµ', 'ë‹­': 'ğŸ”', 'ê°œ': 'ğŸ¶', 'ë¼ì§€': 'ğŸ·'}
            for item in zodiac_horoscopes:
                item['emoji'] = zodiac_emojis.get(item['name'], 'â“')
        # ---

        # --- 3. ë‰´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘ ë° ì²˜ë¦¬ ---
        previous_top_news = load_newsletter_history()
        
        # âœ¨ [ìˆ˜ì •] ë¶„ë¦¬ëœ í•¨ìˆ˜ë¥¼ ì¼ê°„ìš© ì„¤ì •ìœ¼ë¡œ ìˆœì„œëŒ€ë¡œ í˜¸ì¶œ
        candidate_articles = news_service.fetch_candidate_articles(
            keywords=config.KEYWORD_GROUPS_DAILY, 
            hours=config.NEWS_FETCH_HOURS_DAILY
        )
        all_news = news_service.process_articles(candidate_articles, driver_path)
        
        if not all_news:
            print("â„¹ï¸ ë°œì†¡í•  ìƒˆë¡œìš´ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        top_news = ai_service.select_top_news(all_news, previous_top_news, count=config.SELECT_NEWS_COUNT_DAILY)
        
        if not top_news:
            print("â„¹ï¸ AIê°€ ë‰´ìŠ¤ë¥¼ ì„ ë³„í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

        ai_briefing_md = ai_service.generate_briefing(top_news, mode='daily')
        ai_briefing_html = markdown_to_html(ai_briefing_md)
        
        # --- 4. í…œí”Œë¦¿ì— ì „ë‹¬í•  ìµœì¢… ë°ì´í„° ì¤€ë¹„ ---
        title_text = "ë¡œë””ì™€ í•¨ê»˜í•˜ëŠ” ì˜¤ëŠ˜ì˜ ë¬¼ë¥˜ ì‚°ì±…"
        if price_chart_result: price_indicators['price_chart_b64'] = price_chart_result['base64']
        weather_dashboard_b64 = weather_result['base64'] if weather_result else None
        
        web_news_list = []
        for news in top_news:
            news_copy = news.copy()
            if news_copy.get('image_data'):
                news_copy['image_src'] = f"data:image/jpeg;base64,{base64.b64encode(news_copy['image_data']).decode('utf-8')}"
            web_news_list.append(news_copy)

        context = {
            "title": title_text,
            "today_date": today_str,
            "ai_briefing": ai_briefing_html,
            "risk_briefing_html": risk_briefing_html,
            "price_indicators": price_indicators,
            "news_list": web_news_list,
            "weather_dashboard_b64": weather_dashboard_b64,
            "has_weather_dashboard": True if weather_dashboard_b64 else False,
            "zodiac_horoscopes": zodiac_horoscopes
        }
        
        # --- 5. HTML ìƒì„± ë° ì´ë©”ì¼ ë°œì†¡ ---
        web_html = render_html_template(context, target='web')
        archive_filepath = f"archive/{today_str}.html"
        with open(archive_filepath, 'w', encoding='utf-8') as f: f.write(web_html)
        print(f"âœ… ì›¹í˜ì´ì§€ ë²„ì „ì„ '{archive_filepath}'ì— ì €ì¥í–ˆìŠµë‹ˆë‹¤.")

        for i, news_item in enumerate(top_news):
            if news_item.get('image_data'): news_item['image_cid'] = f'news_image_{i}'
        
        context['news_list'] = top_news
        email_body = render_html_template(context, target='email')
        email_subject = f"[{today_str}] {title_text}"
        
        images_to_embed = []
        if price_chart_result and price_chart_result.get('filepath'):
            images_to_embed.append({'path': price_chart_result['filepath'], 'cid': 'price_chart'})
        if weather_result and weather_result.get('filepath'):
            images_to_embed.append({'path': weather_result['filepath'], 'cid': 'weather_dashboard'})
        for news_item in top_news:
            if news_item.get('image_data') and news_item.get('image_cid'):
                images_to_embed.append({'data': news_item['image_data'], 'cid': news_item['image_cid']})
        
        # ë‰´ìŠ¤ë ˆí„° ë°°ë„ˆ ì´ë¯¸ì§€ë¥¼ ì²¨ë¶€í•©ë‹ˆë‹¤.
        banner_path = "assets/logicharacter.png"
        if os.path.exists(banner_path):
            images_to_embed.append({'path': banner_path, 'cid': 'newsletter_banner'})

         # ìš´ì„¸ ìºë¦­í„° ì´ë¯¸ì§€ë¥¼ ì²¨ë¶€í•©ë‹ˆë‹¤.
        fortune_char_path = "assets/fortunechar.png"
        if os.path.exists(fortune_char_path):
            images_to_embed.append({'path': fortune_char_path, 'cid': 'furtunechar.png'})    
        
        email_service.send_email(email_subject, email_body, images_to_embed)
        
        # --- 6. ìƒíƒœ ì €ì¥ ë° ë§ˆë¬´ë¦¬ ---
        if top_news:
            news_service.update_sent_links_log(top_news)
            save_newsletter_history(top_news)
        update_archive_index()

        #ì£¼ê°„ ë‰´ìŠ¤ë ˆí„° í›„ë³´êµ°ìœ¼ë¡œ ì˜¤ëŠ˜ì˜ ê¸°ì‚¬ë¥¼ ì €ì¥
        try:
            #ê¸°ì¡´ í›„ë³´ íŒŒì¼ì´ ìˆìœ¼ë©´ ë¶ˆëŸ¬ì˜¤ê³ , ì—†ìœ¼ë©´ ë¹ˆê±¸ë¡œ ì‹œì‘
            try:
                with open(config.WEEKLY_CANDIDATES_FILE, 'r', encoding='utf-8') as f:
                    all_candidates = json.load(f)
            except (FileNotFoundError, json.JSONDecodeError):
                all_candidates=[]
            
            # ì˜¤ëŠ˜ ë°œì†¡ëœ ë‰´ìŠ¤ ì¶”ê°€(ì´ë¯¸ì§€ ë°ì´í„°ëŠ” ì œì™¸)
            for news in top_news:
                news_to_save = {k: v for k, v in news.items() if k != 'image_data'}
                all_candidates.append(news_to_save)
            #ì „ì²´ í›„ë³´ ë‹¤ì‹œ íŒŒì¼ì— ì €ì¥
            with open(config.WEEKLY_CANDIDATES_FILE, 'w', encoding='utf-8') as f:
                json.dump(all_candidates, f, ensure_ascii=False, indent=4)
            print(f"âœ… ì£¼ê°„ í›„ë³´ ë‰´ìŠ¤ë¡œ {len(top_news)}ê°œë¥¼ ì €ì¥í–ˆìŠµë‹ˆë‹¤. (ì´ {len(all_candidates)}ê°œ)")

        except Exception as e:
            print(f"âŒ ì£¼ê°„ í›„ë³´ ë‰´ìŠ¤ ì €ì¥ ì‹¤íŒ¨: {e}")

        print("\nğŸ‰ ì¼ê°„ ë‰´ìŠ¤ë ˆí„° í”„ë¡œì„¸ìŠ¤ê°€ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        import traceback
        traceback.print_exc()
        print(f"ğŸ”¥ ì¼ê°„ ë‰´ìŠ¤ë ˆí„° ìƒì„± ì¤‘ ì¹˜ëª…ì ì¸ ì˜¤ë¥˜ ë°œìƒ: {e.__class__.__name__}: {e}")


def run_weekly_newsletter(config, driver_path):
    """ì£¼ê°„ ë‰´ìŠ¤ë ˆí„° ìƒì„±ì˜ ëª¨ë“  ê³¼ì •ì„ ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜"""
    print("ğŸš€ ì£¼ê°„ ë‰´ìŠ¤ë ˆí„° ìƒì„±ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
    try:
        # --- 1. ì„œë¹„ìŠ¤ ê°ì²´ ì´ˆê¸°í™” ---
        news_service = NewsService(config)
        email_service = EmailService(config)
        weather_service = WeatherService(config)
        risk_briefing_service = RiskBriefingService()
        ai_service = AIService(config)
        
        week_str = get_kst_week_str()
        os.makedirs('archive', exist_ok=True)
        os.makedirs('images', exist_ok=True)

        # --- 2. ë³´ì¡° ë°ì´í„° ìƒì„± (ìœ ê°€, ë‚ ì”¨, ë¦¬ìŠ¤í¬) ---
        price_indicators = get_price_indicators(config)
        weather_result = weather_service.create_dashboard_image(week_str)
        price_chart_result = create_price_trend_chart(price_indicators.get("seven_day_data"), week_str) if price_indicators.get("seven_day_data") else None
        
        risk_events = risk_briefing_service.generate_risk_events()
        risk_briefing_md = ai_service.generate_risk_briefing(risk_events)
        risk_briefing_html = markdown_to_html(risk_briefing_md) if risk_briefing_md else None

        # âœ¨ [ì‹ ê·œ] ë ë³„ ìš´ì„¸ ë°ì´í„° ìƒì„± ë° ê°€ê³µ ---
        zodiac_horoscopes = ai_service.generate_zodiac_horoscopes()
        if zodiac_horoscopes:
            zodiac_emojis = {'ì¥': 'ğŸ­', 'ì†Œ': 'ğŸ®', 'í˜¸ë‘ì´': 'ğŸ¯', 'í† ë¼': 'ğŸ°', 'ìš©': 'ğŸ²', 'ë±€': 'ğŸ', 'ë§': 'ğŸ´', 'ì–‘': 'ğŸ‘', 'ì›ìˆ­ì´': 'ğŸµ', 'ë‹­': 'ğŸ”', 'ê°œ': 'ğŸ¶', 'ë¼ì§€': 'ğŸ·'}
            for item in zodiac_horoscopes:
                item['emoji'] = zodiac_emojis.get(item['name'], 'â“')
        # ---

        # --- 3. ë‰´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘ ë° ì²˜ë¦¬ (ì£¼ê°„ìš© ì„¤ì • ì‚¬ìš©) ---
        previous_top_news = load_newsletter_history(filepath='previous_weekly_newsletter.json')
        
        
        # âœ¨ [ìˆ˜ì •] íŒŒì¼ì´ ìˆìœ¼ë©´ ì½ê³ , ì—†ìœ¼ë©´ ì›¹ì—ì„œ ìˆ˜ì§‘í•˜ëŠ” Fallback ë¡œì§ì„ ì¶”ê°€í•©ë‹ˆë‹¤.
        all_news = []
        try:
            with open(config.WEEKLY_CANDIDATES_FILE, 'r', encoding='utf-8') as f:
                all_news = json.load(f)
            if not all_news:
                # íŒŒì¼ì€ ìˆì§€ë§Œ ë‚´ìš©ì´ ë¹„ì–´ìˆëŠ” ê²½ìš°ë¥¼ ìœ„í•´ ì—ëŸ¬ ë°œìƒ
                raise FileNotFoundError("ì£¼ê°„ í›„ë³´ íŒŒì¼ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
            print(f"âœ… ì£¼ê°„ í›„ë³´ ë‰´ìŠ¤ {len(all_news)}ê°œë¥¼ íŒŒì¼ì—ì„œ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.")
        except (FileNotFoundError, json.JSONDecodeError):
            print(f"âš ï¸ ì£¼ê°„ í›„ë³´ íŒŒì¼ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ì–´ ì›¹ì—ì„œ ì§ì ‘ ë‰´ìŠ¤ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤ (Fallback).")
            # --- Fallback: ê¸°ì¡´ì˜ ì›¹ ìŠ¤í¬ë˜í•‘ ë¡œì§ ì‹¤í–‰ ---
            candidate_articles = news_service.fetch_candidate_articles(
                keywords=config.KEYWORD_GROUPS_WEEKLY, 
                hours=config.NEWS_FETCH_HOURS_WEEKLY
        )
        all_news = news_service.process_articles(candidate_articles, driver_path)
        
        top_news = ai_service.select_top_news(all_news, previous_top_news, count=config.SELECT_NEWS_COUNT_WEEKLY)
        
        if not top_news:
            print("â„¹ï¸ AIê°€ ì£¼ê°„ ë‰´ìŠ¤ë¥¼ ì„ ë³„í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. (ë˜ëŠ” ìˆ˜ì§‘ëœ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤)")

        ai_briefing_md = ai_service.generate_briefing(top_news, mode='weekly')
        ai_briefing_html = markdown_to_html(ai_briefing_md)
        
        # --- 4. í…œí”Œë¦¿ì— ì „ë‹¬í•  ìµœì¢… ë°ì´í„° ì¤€ë¹„ ---
        title_text = "ë¡œë””ì™€ í•¨ê»˜í•˜ëŠ” ì£¼ê°„ ë¬¼ë¥˜ ì‚°ì±…"
        if price_chart_result: price_indicators['price_chart_b64'] = price_chart_result['base64']
        weather_dashboard_b64 = weather_result['base64'] if weather_result else None
        
        web_news_list = []
        for news in top_news:
            news_copy = news.copy()
            if news_copy.get('image_data'):
                news_copy['image_src'] = f"data:image/jpeg;base64,{base64.b64encode(news_copy['image_data']).decode('utf-8')}"
            web_news_list.append(news_copy)

        context = {
            "title": title_text,
            "today_date": week_str,
            "ai_briefing": ai_briefing_html,
            "risk_briefing_html": risk_briefing_html,
            "price_indicators": price_indicators,
            "news_list": web_news_list,
            "weather_dashboard_b64": weather_dashboard_b64,
            "has_weather_dashboard": True if weather_dashboard_b64 else False,
            "zodiac_horoscopes": zodiac_horoscopes
        }
        
        # --- 5. HTML ìƒì„± ë° ì´ë©”ì¼ ë°œì†¡ ---
        web_html = render_html_template(context, target='web')
        archive_filepath = f"archive/{week_str}.html"
        with open(archive_filepath, 'w', encoding='utf-8') as f: f.write(web_html)
        print(f"âœ… ì›¹í˜ì´ì§€ ë²„ì „ì„ '{archive_filepath}'ì— ì €ì¥í–ˆìŠµë‹ˆë‹¤.")

        for i, news_item in enumerate(top_news):
            if news_item.get('image_data'): news_item['image_cid'] = f'news_image_{i}'
        
        context['news_list'] = top_news
        email_body = render_html_template(context, target='email')
        email_subject = f"[{week_str}] {title_text} ìš”ì•½"
        
        images_to_embed = []
        if price_chart_result and price_chart_result.get('filepath'):
            images_to_embed.append({'path': price_chart_result['filepath'], 'cid': 'price_chart'})
        if weather_result and weather_result.get('filepath'):
            images_to_embed.append({'path': weather_result['filepath'], 'cid': 'weather_dashboard'})
        for news_item in top_news:
            if news_item.get('image_data') and news_item.get('image_cid'):
                images_to_embed.append({'data': news_item['image_data'], 'cid': news_item['image_cid']})
        

        # ë‰´ìŠ¤ë ˆí„° ë°°ë„ˆ ì´ë¯¸ì§€ë¥¼ ì²¨ë¶€í•©ë‹ˆë‹¤.
        banner_path = "assets/logicharacter.png"
        if os.path.exists(banner_path):
            images_to_embed.append({'path': banner_path, 'cid': 'newsletter_banner'})


         # ìš´ì„¸ ìºë¦­í„° ì´ë¯¸ì§€ë¥¼ ì²¨ë¶€í•©ë‹ˆë‹¤.
        fortune_char_path = "assets/fortunechar.png"
        if os.path.exists(fortune_char_path):
            images_to_embed.append({'path': fortune_char_path, 'cid': 'furtunechar.png'})        
        
        email_service.send_email(email_subject, email_body, images_to_embed)
        
        # --- 6. ìƒíƒœ ì €ì¥ ë° ë§ˆë¬´ë¦¬ ---
        if top_news:
            news_service.update_sent_links_log(top_news)
            save_newsletter_history(top_news, filepath='previous_weekly_newsletter.json')
        update_archive_index()

        try:
            with open(config.WEEKLY_CANDIDATES_FILE, 'w', encoding='utf-8') as f:
                json.dump([], f) # ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¥¼ íŒŒì¼ì— ë®ì–´ì“°ê¸°
            print(f"âœ… '{config.WEEKLY_CANDIDATES_FILE}' íŒŒì¼ì„ ì´ˆê¸°í™”í–ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            print(f"âŒ ì£¼ê°„ í›„ë³´ ë‰´ìŠ¤ íŒŒì¼ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

        print("\nğŸ‰ ì£¼ê°„ ë‰´ìŠ¤ë ˆí„° í”„ë¡œì„¸ìŠ¤ê°€ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        import traceback
        traceback.print_exc()
        print(f"ğŸ”¥ ì£¼ê°„ ë‰´ìŠ¤ë ˆí„° ìƒì„± ì¤‘ ì¹˜ëª…ì ì¸ ì˜¤ë¥˜ ë°œìƒ: {e.__class__.__name__}: {e}")


def main():
    """ì‹¤í–‰ ëª¨ë“œì— ë”°ë¼ ì ì ˆí•œ ë‰´ìŠ¤ë ˆí„° ìƒì„± í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ëŠ” ì»¨íŠ¸ë¡¤ëŸ¬"""
    print("-> Chrome ë“œë¼ì´ë²„ë¥¼ ì¤€ë¹„í•©ë‹ˆë‹¤...")
    try:
        driver_path = ChromeDriverManager().install()
        print(f"âœ… ë“œë¼ì´ë²„ ì¤€ë¹„ ì™„ë£Œ: {driver_path}")
    except Exception as e:
        print(f"ğŸ”¥ ì¹˜ëª…ì ì¸ ì˜¤ë¥˜ ë°œìƒ: Chrome ë“œë¼ì´ë²„ë¥¼ ì¤€ë¹„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. {e}")
        return

    config = Config()
    
    if config.EXECUTION_MODE == 'weekly':
        run_weekly_newsletter(config, driver_path)
    elif config.EXECUTION_MODE == 'daily':
        run_daily_newsletter(config, driver_path)
    else:
        print(f"âŒ ì•Œ ìˆ˜ ì—†ëŠ” ì‹¤í–‰ ëª¨ë“œì…ë‹ˆë‹¤: '{config.EXECUTION_MODE}'. 'daily' ë˜ëŠ” 'weekly'ë¡œ ì„¤ì •í•´ì£¼ì„¸ìš”.")

def main_for_chart_test():
    """ì˜¤ì§ 'ìœ ê°€ ì¶”ì´ ì°¨íŠ¸' ìƒì„± ê¸°ëŠ¥ë§Œ í…ŒìŠ¤íŠ¸í•˜ëŠ” í•¨ìˆ˜"""
    print("ğŸš€ ìœ ê°€ ì¶”ì´ ì°¨íŠ¸ ìƒì„± í…ŒìŠ¤íŠ¸ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.")
    try:
        # --- 1. í•„ìš”í•œ ê°ì²´ ë° í´ë” ì¤€ë¹„ ---
        config = Config()
        today_str = get_kst_today_str()
        os.makedirs('images', exist_ok=True)

        # --- 2. ìœ ê°€ ë°ì´í„° ìˆ˜ì§‘ ---
        price_indicators = get_price_indicators(config)
        
        # --- 3. ì°¨íŠ¸ ìƒì„± (í…ŒìŠ¤íŠ¸ í•µì‹¬) ---
        if price_indicators.get("seven_day_data"):
            create_price_trend_chart(price_indicators["seven_day_data"], today_str)
        else:
            print("âŒ ì°¨íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” ë° í•„ìš”í•œ 7ì¼ê°„ì˜ ìœ ê°€ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

        print("\nğŸ‰ ì°¨íŠ¸ ìƒì„± í…ŒìŠ¤íŠ¸ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. 'images' í´ë”ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")

    except Exception as e:
        import traceback
        traceback.print_exc()
        print(f"ğŸ”¥ í…ŒìŠ¤íŠ¸ ì¤‘ ì¹˜ëª…ì ì¸ ì˜¤ë¥˜ ë°œìƒ: {e.__class__.__name__}: {e}")




def main_for_horoscope_test():
    """ì˜¤ì§ 'ë ë³„ ìš´ì„¸' ìƒì„± ê¸°ëŠ¥ë§Œ í…ŒìŠ¤íŠ¸í•˜ëŠ” í•¨ìˆ˜"""
    print("ğŸš€ ë ë³„ ìš´ì„¸ ìƒì„± í…ŒìŠ¤íŠ¸ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.")
    try:
        config = Config()
        ai_service = AIService(config)
        
        horoscopes = ai_service.generate_zodiac_horoscopes()
        
        if horoscopes:
            print("\n--- [AI ë ë³„ ìš´ì„¸ ìƒì„± ê²°ê³¼] ---")
            for h in horoscopes:
                print(f"\n[ {h.get('name')}ë  ]")
                print(f"  - ìš´ì„¸: {h.get('fortune')}")
                print(f"  - í–‰ìš´ìƒ‰: {h.get('lucky_color')}")
                print(f"  - ê¶í•©: {h.get('compatible_sign')}")
            print("\n---------------------------------")
        else:
            print("âŒ ìš´ì„¸ ë°ì´í„°ë¥¼ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

        print("\nğŸ‰ ë ë³„ ìš´ì„¸ ìƒì„± í…ŒìŠ¤íŠ¸ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        print(f"ğŸ”¥ í…ŒìŠ¤íŠ¸ ì¤‘ ì¹˜ëª…ì ì¸ ì˜¤ë¥˜ ë°œìƒ: {e.__class__.__name__}: {e}")


def test_render_horoscope_email():
    """ìƒ˜í”Œ ë°ì´í„°ë¡œ ë ë³„ ìš´ì„¸ ì„¹ì…˜ì´ í¬í•¨ëœ HTML íŒŒì¼ì„ ìƒì„±í•˜ì—¬ ì‹œê°ì ìœ¼ë¡œ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤."""
    print("ğŸš€ ë ë³„ ìš´ì„¸ ì´ë©”ì¼ ë Œë”ë§ í…ŒìŠ¤íŠ¸ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.")
    try:
        # 1. Jinja2 í…œí”Œë¦¿ í™˜ê²½ì„ ì„¤ì •í•©ë‹ˆë‹¤.
        env = Environment(loader=FileSystemLoader('.'))
        template = env.get_template('email_template.html')

        # 2. 'ë¡œë””' í˜ë¥´ì†Œë‚˜ë¥¼ í‰ë‚´ ë‚¸ ìƒ˜í”Œ ìš´ì„¸ ë°ì´í„°ë¥¼ ë§Œë“­ë‹ˆë‹¤.
        sample_horoscopes = [
            {
                'name': 'ì¥', 'emoji': 'ğŸ­',
                'fortune': 'ì˜¤ëŠ˜ì€ ìƒˆë¡œìš´ ì•„ì´ë””ì–´ê°€ ìƒ˜ì†ŸëŠ” í•˜ë£¨ê°€ ë  ê±°ì˜ˆìš”! ë°˜ì§ì´ëŠ” ìƒê°ì„ ë†“ì¹˜ì§€ ë§ê³  ê¼­ ë©”ëª¨í•´ë‘ì„¸ìš”. ë¶„ëª… ì¢‹ì€ ê²°ê³¼ë¡œ ì´ì–´ì§ˆ ê±°ëë‹ˆë‹¤.',
                'lucky_color': 'ë…¸ë‘', 'compatible_sign': 'ìš©'
            },
            {
                'name': 'í˜¸ë‘ì´', 'emoji': 'ğŸ¯',
                'fortune': 'ì£¼ë³€ ì‚¬ëŒë“¤ì—ê²Œ ë”°ëœ»í•œ ë§ì„ ê±´ë„¤ë©´ í–‰ìš´ì´ ì°¾ì•„ì˜¨ëŒ€ìš”! ì˜¤ëŠ˜ì€ ì œê°€ ë¨¼ì € ë‹¤ê°€ê°€ì„œ í˜ì´ ë˜ì–´ì£¼ëŠ” ë©‹ì§„ í•˜ë£¨ë¥¼ ë§Œë“¤ì–´ ë´ìš”!',
                'lucky_color': 'ì´ˆë¡', 'compatible_sign': 'ë§'
            },
            {
                'name': 'ë¼ì§€', 'emoji': 'ğŸ·',
                'fortune': 'ê·¸ë™ì•ˆ ë…¸ë ¥í•´ì™”ë˜ ì¼ì— ëŒ€í•œ ë³´ìƒì„ ë°›ê²Œ ë  ê²ƒ ê°™ì€ ì¢‹ì€ ì˜ˆê°ì´ ë“¤ì–´ìš”. ì¡°ê¸ˆë§Œ ë” í˜ë‚´ì„¸ìš”! ë§›ìˆëŠ” ì €ë…ì„ ê¸°ëŒ€í•´ë„ ì¢‹ì„ì§€ë„? ğŸ˜‹',
                'lucky_color': 'ì£¼í™©', 'compatible_sign': 'í† ë¼'
            }
        ]

        # 3. í…œí”Œë¦¿ì— ì „ë‹¬í•  context ë°ì´í„°ë¥¼ êµ¬ì„±í•©ë‹ˆë‹¤.
        #    - ë‹¤ë¥¸ ê°’ë“¤ì€ ë¹„ì›Œë‘ê³  ìš´ì„¸ ë°ì´í„°ë§Œ ë„£ì–´ì„œ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.
        context = {
            "title": "í…ŒìŠ¤íŠ¸: ë ë³„ ìš´ì„¸ ë¯¸ë¦¬ë³´ê¸°",
            "today_date": get_kst_today_str(),
            "ai_briefing": None, "risk_briefing_html": None,
            "price_indicators": None, "news_list": [],
            "weather_dashboard_b64": None, "has_weather_dashboard": False,
            "zodiac_horoscopes": sample_horoscopes
        }

        # 4. í…œí”Œë¦¿ì„ ë Œë”ë§í•˜ì—¬ HTML íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
        rendered_html = template.render(context)
        output_filename = 'horoscope_email_preview.html'
        with open(output_filename, 'w', encoding='utf-8') as f:
            f.write(rendered_html)

        print(f"\nâœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ! '{output_filename}' íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
        print("   ì´ íŒŒì¼ì„ ì›¹ ë¸Œë¼ìš°ì €ë¡œ ì—´ì–´ì„œ ì–´ë–»ê²Œ ë³´ì´ëŠ”ì§€ í™•ì¸í•´ë³´ì„¸ìš”.")

    except Exception as e:
        import traceback
        traceback.print_exc()
        print(f"ğŸ”¥ í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")


if __name__ == "__main__":
    main()
    #main_for_horoscope_test()
    #test_render_horoscope_email()


